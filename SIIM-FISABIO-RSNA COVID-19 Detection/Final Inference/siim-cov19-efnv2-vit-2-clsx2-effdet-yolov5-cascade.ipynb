{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ranging-venture",
   "metadata": {
    "papermill": {
     "duration": 0.071383,
     "end_time": "2021-08-02T09:13:06.992195",
     "exception": false,
     "start_time": "2021-08-02T09:13:06.920812",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Version\n",
    "\n",
    "* `v1`: \n",
    "    classification: tf_efficientnetv2_m_in21k_fold0_epoch17_colab_pseudo_labeling_v5.pt, tf_efficientnetv2_m_in21k_fold1_epoch0_colab_v33.pt, tf_efficientnetv2_m_in21k_fold2_epoch6_colab_pseudo_labeling_v7.pt, tf_efficientnetv2_m_in21k_fold3_epoch15_colab_pseudo_labeling_v8.pt, tf_efficientnetv2_m_in21k_fold4_epoch26_colab_pseudo_labeling_v9.pt, vit_deit_base_patch16_384_fold0_epoch10_colab_vit_v7.pt, vit_deit_base_patch16_384_fold1_epoch9_colab_vit_v9.pt, vit_deit_base_patch16_384_fold2_epoch14_colab_vit_v11.pt, vit_deit_base_patch16_384_fold3_epoch6_colab_vit_v12.pt, vit_deit_base_patch16_384_fold4_epoch13_colab_vit_v13.pt weights=[38,38,38,38,38,37,37,37,37,37] 3_tta\n",
    "    \n",
    "    2-class: tf_efficientnet_v2 + vit_deit_base_patch16_384_fold0_epoch8_colab_v6.pt + vit_deit_base_patch16_384_fold1_epoch8_colab_v7.pt + vit_deit_base_patch16_384_fold2_epoch9_colab_v8.pt weights=[59,59,59,59,59,58,58,58] 3_tta\n",
    "    \n",
    "    detection: yolov5x_fold0_nb_v14_best.pt + yolov5x_fold1_nb_v19_best.pt + yolov5x_fold2_nb_v20_best.pt + siimcovid19-effdet/effdet5_640_fold3_epoch20.bin + siimcovid19-effdet/effdet5_640_fold4_epoch24.bin nms_0.5 img_640 + cascade_rcnn_x101_32x4d_fpn_1x_fold0_epoch10_public_nb_v8.pth nms_iou_0.5 wbf iou=0.6 weight=[54,54,54,54,54,58,58,58,58,58,54] skipbox_thr=0.01 tta (1 - none_score) ** 0.5 img_640"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "advisory-terrace",
   "metadata": {
    "papermill": {
     "duration": 0.074261,
     "end_time": "2021-08-02T09:13:07.142103",
     "exception": false,
     "start_time": "2021-08-02T09:13:07.067842",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Note:\n",
    "- df_2class and sub_df should be merged by id, not sub_df['none'] = df_2class['none'] because there might be a mix of ids"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "architectural-latest",
   "metadata": {
    "papermill": {
     "duration": 0.073952,
     "end_time": "2021-08-02T09:13:07.287243",
     "exception": false,
     "start_time": "2021-08-02T09:13:07.213291",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "thanks to https://www.kaggle.com/xhlulu/siim-covid-19-convert-to-jpg-256px  \n",
    "thanks to https://www.kaggle.com/awsaf49/vinbigdata-cxr-ad-yolov5-14-class-infer  \n",
    "train_study: https://www.kaggle.com/h053473666/siim-covid19-efnb7-train-study  \n",
    "train_image: https://www.kaggle.com/h053473666/siim-cov19-yolov5-train  \n",
    "train_2class: https://www.kaggle.com/h053473666/siim-covid19-efnb7-train-fold0-5-2class  \n",
    "  \n",
    "version1:Original hyperparameters (yolov5)  \n",
    "version4:New hyperparameters (yolov5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dominican-bermuda",
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2021-08-02T09:13:07.439531Z",
     "iopub.status.busy": "2021-08-02T09:13:07.437760Z",
     "iopub.status.idle": "2021-08-02T09:14:16.685739Z",
     "shell.execute_reply": "2021-08-02T09:14:16.685098Z",
     "shell.execute_reply.started": "2021-08-01T23:12:57.243956Z"
    },
    "papermill": {
     "duration": 69.324269,
     "end_time": "2021-08-02T09:14:16.685891",
     "exception": false,
     "start_time": "2021-08-02T09:13:07.361622",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Downloading and Extracting Packages\r\n",
      "######################################################################## | 100% \r\n",
      "Preparing transaction: - \b\bdone\r\n",
      "Verifying transaction: | \b\bdone\r\n",
      "Executing transaction: - \b\b\\ \b\bdone\r\n",
      "\r\n",
      "Downloading and Extracting Packages\r\n",
      "######################################################################## | 100% \r\n",
      "Preparing transaction: - \b\bdone\r\n",
      "Verifying transaction: | \b\bdone\r\n",
      "Executing transaction: - \b\b\\ \b\b| \b\bdone\r\n",
      "\r\n",
      "Downloading and Extracting Packages\r\n",
      "######################################################################## | 100% \r\n",
      "Preparing transaction: - \b\bdone\r\n",
      "Verifying transaction: | \b\bdone\r\n",
      "Executing transaction: - \b\bdone\r\n",
      "\r\n",
      "Downloading and Extracting Packages\r\n",
      "######################################################################## | 100% \r\n",
      "Preparing transaction: - \b\bdone\r\n",
      "Verifying transaction: | \b\bdone\r\n",
      "Executing transaction: - \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\bdone\r\n",
      "\r\n",
      "Downloading and Extracting Packages\r\n",
      "######################################################################## | 100% \r\n",
      "Preparing transaction: - \b\bdone\r\n",
      "Verifying transaction: | \b\bdone\r\n",
      "Executing transaction: - \b\bdone\r\n",
      "\r\n",
      "Downloading and Extracting Packages\r\n",
      "######################################################################## | 100% \r\n",
      "Preparing transaction: - \b\bdone\r\n",
      "Verifying transaction: | \b\bdone\r\n",
      "Executing transaction: - \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\bdone\r\n"
     ]
    }
   ],
   "source": [
    "!conda install '/kaggle/input/pydicom-conda-helper/libjpeg-turbo-2.1.0-h7f98852_0.tar.bz2' -c conda-forge -y\n",
    "!conda install '/kaggle/input/pydicom-conda-helper/libgcc-ng-9.3.0-h2828fa1_19.tar.bz2' -c conda-forge -y\n",
    "!conda install '/kaggle/input/pydicom-conda-helper/gdcm-2.8.9-py37h500ead1_1.tar.bz2' -c conda-forge -y\n",
    "!conda install '/kaggle/input/pydicom-conda-helper/conda-4.10.1-py37h89c1867_0.tar.bz2' -c conda-forge -y\n",
    "!conda install '/kaggle/input/pydicom-conda-helper/certifi-2020.12.5-py37h89c1867_1.tar.bz2' -c conda-forge -y\n",
    "!conda install '/kaggle/input/pydicom-conda-helper/openssl-1.1.1k-h7f98852_0.tar.bz2' -c conda-forge -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "placed-agency",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-02T09:14:16.858584Z",
     "iopub.status.busy": "2021-08-02T09:14:16.857795Z",
     "iopub.status.idle": "2021-08-02T09:14:39.033246Z",
     "shell.execute_reply": "2021-08-02T09:14:39.033701Z",
     "shell.execute_reply.started": "2021-08-01T23:14:06.005849Z"
    },
    "papermill": {
     "duration": 22.264155,
     "end_time": "2021-08-02T09:14:39.033879",
     "exception": false,
     "start_time": "2021-08-02T09:14:16.769724",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install --no-deps '../input/pycocotools/pycocotools-2.0-cp37-cp37m-linux_x86_64.whl' > /dev/null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "future-paste",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-02T09:14:39.222614Z",
     "iopub.status.busy": "2021-08-02T09:14:39.221741Z",
     "iopub.status.idle": "2021-08-02T09:14:39.224019Z",
     "shell.execute_reply": "2021-08-02T09:14:39.224470Z",
     "shell.execute_reply.started": "2021-08-01T23:14:28.150737Z"
    },
    "papermill": {
     "duration": 0.098733,
     "end_time": "2021-08-02T09:14:39.224607",
     "exception": false,
     "start_time": "2021-08-02T09:14:39.125874",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "package_paths = [\n",
    "    '../input/weighted-boxes-fusion/Weighted-Boxes-Fusion-master',\n",
    "    '../input/pytorchimagemodels/pytorch-image-models-master', #'../input/efficientnet-pytorch-07/efficientnet_pytorch-0.7.0'\n",
    "    \"../input/timmeffdetclsv2/timm-efficientdet-pytorch\",\n",
    "    \"../input/omegaconf\"\n",
    "#     '../input/image-fmix/FMix-master'\n",
    "]\n",
    "import sys; \n",
    "\n",
    "for pth in package_paths:\n",
    "    sys.path.append(pth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "awful-yacht",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2021-08-02T09:14:39.409705Z",
     "iopub.status.busy": "2021-08-02T09:14:39.408948Z",
     "iopub.status.idle": "2021-08-02T09:14:40.144670Z",
     "shell.execute_reply": "2021-08-02T09:14:40.144145Z",
     "shell.execute_reply.started": "2021-08-01T23:14:28.160432Z"
    },
    "papermill": {
     "duration": 0.830048,
     "end_time": "2021-08-02T09:14:40.144808",
     "exception": false,
     "start_time": "2021-08-02T09:14:39.314760",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "from ensemble_boxes import *\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "operational-jesus",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-02T09:14:40.343791Z",
     "iopub.status.busy": "2021-08-02T09:14:40.343154Z",
     "iopub.status.idle": "2021-08-02T09:14:40.358828Z",
     "shell.execute_reply": "2021-08-02T09:14:40.358382Z",
     "shell.execute_reply.started": "2021-08-01T23:14:28.839101Z"
    },
    "papermill": {
     "duration": 0.113603,
     "end_time": "2021-08-02T09:14:40.358948",
     "exception": false,
     "start_time": "2021-08-02T09:14:40.245345",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('../input/siim-covid19-detection/sample_submission.csv')\n",
    "if df.shape[0] == 2477:\n",
    "    fast_sub = True\n",
    "    fast_df = pd.DataFrame(([['00086460a852_study', 'negative 1 0 0 1 1'], \n",
    "                         ['000c9c05fd14_study', 'negative 1 0 0 1 1'], \n",
    "                         ['65761e66de9f_image', 'none 1 0 0 1 1'], \n",
    "                         ['51759b5579bc_image', 'none 1 0 0 1 1']]), \n",
    "                       columns=['id', 'PredictionString'])\n",
    "else:\n",
    "    fast_sub = False\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "saving-knight",
   "metadata": {
    "papermill": {
     "duration": 0.087585,
     "end_time": "2021-08-02T09:14:40.535990",
     "exception": false,
     "start_time": "2021-08-02T09:14:40.448405",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# .dcm to .png"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "norman-briefs",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-02T09:14:40.721548Z",
     "iopub.status.busy": "2021-08-02T09:14:40.720906Z",
     "iopub.status.idle": "2021-08-02T09:14:40.873947Z",
     "shell.execute_reply": "2021-08-02T09:14:40.874378Z",
     "shell.execute_reply.started": "2021-08-01T23:14:28.859494Z"
    },
    "papermill": {
     "duration": 0.250763,
     "end_time": "2021-08-02T09:14:40.874579",
     "exception": false,
     "start_time": "2021-08-02T09:14:40.623816",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pydicom\n",
    "from pydicom.pixel_data_handlers.util import apply_voi_lut\n",
    "\n",
    "def read_xray(path, voi_lut = True, fix_monochrome = True):\n",
    "    # Original from: https://www.kaggle.com/raddar/convert-dicom-to-np-array-the-correct-way\n",
    "    dicom = pydicom.read_file(path)\n",
    "    \n",
    "    # VOI LUT (if available by DICOM device) is used to transform raw DICOM data to \n",
    "    # \"human-friendly\" view\n",
    "    if voi_lut:\n",
    "        data = apply_voi_lut(dicom.pixel_array, dicom)\n",
    "    else:\n",
    "        data = dicom.pixel_array\n",
    "               \n",
    "    # depending on this value, X-ray may look inverted - fix that:\n",
    "    if fix_monochrome and dicom.PhotometricInterpretation == \"MONOCHROME1\":\n",
    "        data = np.amax(data) - data\n",
    "        \n",
    "    data = data - np.min(data)\n",
    "    data = data / np.max(data)\n",
    "    data = (data * 255).astype(np.uint8)\n",
    "        \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "protective-dynamics",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-02T09:14:41.064484Z",
     "iopub.status.busy": "2021-08-02T09:14:41.063419Z",
     "iopub.status.idle": "2021-08-02T09:14:41.066428Z",
     "shell.execute_reply": "2021-08-02T09:14:41.065945Z",
     "shell.execute_reply.started": "2021-08-01T23:14:29.112789Z"
    },
    "papermill": {
     "duration": 0.102944,
     "end_time": "2021-08-02T09:14:41.066558",
     "exception": false,
     "start_time": "2021-08-02T09:14:40.963614",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def resize(array, size, keep_ratio=False, resample=Image.LANCZOS):\n",
    "    # Original from: https://www.kaggle.com/xhlulu/vinbigdata-process-and-resize-to-image\n",
    "    im = Image.fromarray(array)\n",
    "    \n",
    "    if keep_ratio:\n",
    "        im.thumbnail((size, size), resample)\n",
    "    else:\n",
    "        im = im.resize((size, size), resample)\n",
    "    \n",
    "    return im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "lovely-michael",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-02T09:14:41.253863Z",
     "iopub.status.busy": "2021-08-02T09:14:41.253109Z",
     "iopub.status.idle": "2021-08-02T09:14:43.037351Z",
     "shell.execute_reply": "2021-08-02T09:14:43.038131Z",
     "shell.execute_reply.started": "2021-08-01T23:14:29.124521Z"
    },
    "papermill": {
     "duration": 1.884182,
     "end_time": "2021-08-02T09:14:43.038410",
     "exception": false,
     "start_time": "2021-08-02T09:14:41.154228",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "split = 'test'\n",
    "save_dir = f'/kaggle/tmp/{split}/'\n",
    "\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "save_dir = f'/kaggle/tmp/{split}/study/'\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "if fast_sub:\n",
    "    xray = read_xray('../input/siim-covid19-detection/train/00086460a852/9e8302230c91/65761e66de9f.dcm')\n",
    "    im = resize(xray, size=640)  \n",
    "    study = '00086460a852' + '_study.png'\n",
    "    im.save(os.path.join(save_dir, study))\n",
    "    xray = read_xray('../input/siim-covid19-detection/train/000c9c05fd14/e555410bd2cd/51759b5579bc.dcm')\n",
    "    im = resize(xray, size=640)  \n",
    "    study = '000c9c05fd14' + '_study.png'\n",
    "    im.save(os.path.join(save_dir, study))\n",
    "else:   \n",
    "    for dirname, _, filenames in tqdm(os.walk(f'../input/siim-covid19-detection/{split}')):\n",
    "        for file in filenames:\n",
    "            # set keep_ratio=True to have original aspect ratio\n",
    "            xray = read_xray(os.path.join(dirname, file))\n",
    "            im = resize(xray, size=640)  \n",
    "            study = dirname.split('/')[-2] + '_study.png'\n",
    "            im.save(os.path.join(save_dir, study))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "organized-active",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-02T09:14:43.396286Z",
     "iopub.status.busy": "2021-08-02T09:14:43.395175Z",
     "iopub.status.idle": "2021-08-02T09:14:43.880408Z",
     "shell.execute_reply": "2021-08-02T09:14:43.879852Z",
     "shell.execute_reply.started": "2021-08-01T23:14:30.862791Z"
    },
    "papermill": {
     "duration": 0.696838,
     "end_time": "2021-08-02T09:14:43.880545",
     "exception": false,
     "start_time": "2021-08-02T09:14:43.183707",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "image_id = []\n",
    "dim0 = []\n",
    "dim1 = []\n",
    "splits = []\n",
    "save_dir = f'/kaggle/tmp/{split}/image/'\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "if fast_sub:\n",
    "    xray = read_xray('../input/siim-covid19-detection/train/00086460a852/9e8302230c91/65761e66de9f.dcm')\n",
    "    im = resize(xray, size=640)  \n",
    "    im.save(os.path.join(save_dir,'65761e66de9f_image.png'))\n",
    "    image_id.append('65761e66de9f.dcm'.replace('.dcm', ''))\n",
    "    dim0.append(xray.shape[0])\n",
    "    dim1.append(xray.shape[1])\n",
    "    splits.append(split)\n",
    "    xray = read_xray('../input/siim-covid19-detection/train/000c9c05fd14/e555410bd2cd/51759b5579bc.dcm')\n",
    "    im = resize(xray, size=640)  \n",
    "    im.save(os.path.join(save_dir, '51759b5579bc_image.png'))\n",
    "    image_id.append('51759b5579bc.dcm'.replace('.dcm', ''))\n",
    "    dim0.append(xray.shape[0])\n",
    "    dim1.append(xray.shape[1])\n",
    "    splits.append(split)\n",
    "else:\n",
    "    for dirname, _, filenames in tqdm(os.walk(f'../input/siim-covid19-detection/{split}')):\n",
    "        for file in filenames:\n",
    "            # set keep_ratio=True to have original aspect ratio\n",
    "            xray = read_xray(os.path.join(dirname, file))\n",
    "            im = resize(xray, size=640)  \n",
    "            im.save(os.path.join(save_dir, file.replace('.dcm', '_image.png')))\n",
    "            image_id.append(file.replace('.dcm', ''))\n",
    "            dim0.append(xray.shape[0])\n",
    "            dim1.append(xray.shape[1])\n",
    "            splits.append(split)\n",
    "meta = pd.DataFrame.from_dict({'image_id': image_id, 'dim0': dim0, 'dim1': dim1, 'split': splits})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "artistic-chamber",
   "metadata": {
    "papermill": {
     "duration": 0.089281,
     "end_time": "2021-08-02T09:14:44.060855",
     "exception": false,
     "start_time": "2021-08-02T09:14:43.971574",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# study predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "interesting-football",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-02T09:14:44.246249Z",
     "iopub.status.busy": "2021-08-02T09:14:44.245433Z",
     "iopub.status.idle": "2021-08-02T09:14:48.105669Z",
     "shell.execute_reply": "2021-08-02T09:14:48.104787Z",
     "shell.execute_reply.started": "2021-08-01T23:14:31.327904Z"
    },
    "papermill": {
     "duration": 3.957618,
     "end_time": "2021-08-02T09:14:48.105808",
     "exception": false,
     "start_time": "2021-08-02T09:14:44.148190",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "from sklearn.model_selection import GroupKFold, StratifiedKFold\n",
    "import cv2\n",
    "from skimage import io\n",
    "import torch\n",
    "from torch import nn\n",
    "import os\n",
    "from datetime import datetime\n",
    "import time\n",
    "import random\n",
    "import cv2\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "from torch.utils.data.sampler import SequentialSampler, RandomSampler\n",
    "from  torch.cuda.amp import autocast, GradScaler\n",
    "\n",
    "import sklearn\n",
    "import warnings\n",
    "import joblib\n",
    "from sklearn.metrics import roc_auc_score, log_loss\n",
    "from sklearn import metrics\n",
    "import warnings\n",
    "import cv2\n",
    "import pydicom\n",
    "import timm #from efficientnet_pytorch import EfficientNet\n",
    "from scipy.ndimage.interpolation import zoom\n",
    "from sklearn.metrics import log_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fatal-weather",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-02T09:14:48.295131Z",
     "iopub.status.busy": "2021-08-02T09:14:48.293512Z",
     "iopub.status.idle": "2021-08-02T09:14:48.295771Z",
     "shell.execute_reply": "2021-08-02T09:14:48.296229Z",
     "shell.execute_reply.started": "2021-08-01T23:14:35.242805Z"
    },
    "papermill": {
     "duration": 0.09953,
     "end_time": "2021-08-02T09:14:48.296415",
     "exception": false,
     "start_time": "2021-08-02T09:14:48.196885",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "CFG = {\n",
    "    'fold_num': 5,\n",
    "    'seed': 2011,\n",
    "    'model_arch': 'tf_efficientnetv2_m_in21k',\n",
    "    'vit_model_arch': 'vit_deit_base_patch16_384',\n",
    "    'img_size': 640,\n",
    "    'epochs': 10,\n",
    "    'train_bs': 32,\n",
    "    'valid_bs': 32,\n",
    "    'lr': 1e-4,\n",
    "    'num_workers': 4,\n",
    "    'accum_iter': 1, # suppoprt to do batch accumulation for backprop with effectively larger batch size\n",
    "    'verbose_step': 1,\n",
    "    'device': 'cuda:0',\n",
    "    'tta': 3,\n",
    "    'model_paths': ['../input/siimcovid19-pseudo-labeling-classification/tf_efficientnetv2_m_in21k_fold0_epoch17_colab_pseudo_labeling_v5.pt',\n",
    "                   '../input/siim-covid19-efficientnet/tf_efficientnetv2_m_in21k_fold1_epoch0_colab_v33.pt',\n",
    "                   '../input/siimcovid19-pseudo-labeling-classification/tf_efficientnetv2_m_in21k_fold2_epoch6_colab_pseudo_labeling_v7.pt',\n",
    "                   '../input/siimcovid19-pseudo-labeling-classification/tf_efficientnetv2_m_in21k_fold3_epoch15_colab_pseudo_labeling_v8.pt',\n",
    "                   '../input/siimcovid19-pseudo-labeling-classification/tf_efficientnetv2_m_in21k_fold4_epoch26_colab_pseudo_labeling_v9.pt',\n",
    "                   '../input/siimcovid19-vision-transformer-model/vit_deit_base_patch16_384_fold0_epoch10_colab_vit_v7.pt',\n",
    "                   '../input/siimcovid19-vision-transformer-model/vit_deit_base_patch16_384_fold1_epoch9_colab_vit_v9.pt',\n",
    "                   '../input/siimcovid19-vision-transformer-model/vit_deit_base_patch16_384_fold2_epoch14_colab_vit_v11.pt',\n",
    "                   '../input/siimcovid19-vision-transformer-model/vit_deit_base_patch16_384_fold3_epoch6_colab_vit_v12.pt',\n",
    "                   '../input/siimcovid19-vision-transformer-model/vit_deit_base_patch16_384_fold4_epoch13_colab_vit_v13.pt'],\n",
    "    'num_classes': 4,\n",
    "    'weights': [38, 38, 38, 38, 38, 37, 37, 37, 37, 37]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "exterior-electronics",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-02T09:14:48.478118Z",
     "iopub.status.busy": "2021-08-02T09:14:48.477348Z",
     "iopub.status.idle": "2021-08-02T09:14:48.481172Z",
     "shell.execute_reply": "2021-08-02T09:14:48.480682Z",
     "shell.execute_reply.started": "2021-08-01T23:14:35.252782Z"
    },
    "papermill": {
     "duration": 0.097991,
     "end_time": "2021-08-02T09:14:48.481296",
     "exception": false,
     "start_time": "2021-08-02T09:14:48.383305",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    \n",
    "def get_img(path):\n",
    "    im_bgr = cv2.imread(path)\n",
    "    im_rgb = im_bgr[:, :, ::-1]\n",
    "    #print(im_rgb)\n",
    "    return im_rgb\n",
    "\n",
    "# img = get_img('../input/siim-covid19-resized-to-512px-png/test/0026720152f5.png')\n",
    "# plt.imshow(img)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "finished-handle",
   "metadata": {
    "papermill": {
     "duration": 0.089912,
     "end_time": "2021-08-02T09:14:48.659305",
     "exception": false,
     "start_time": "2021-08-02T09:14:48.569393",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "opponent-connection",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-02T09:14:48.874119Z",
     "iopub.status.busy": "2021-08-02T09:14:48.872471Z",
     "iopub.status.idle": "2021-08-02T09:14:48.889266Z",
     "shell.execute_reply": "2021-08-02T09:14:48.889971Z",
     "shell.execute_reply.started": "2021-08-01T23:14:35.263884Z"
    },
    "papermill": {
     "duration": 0.139171,
     "end_time": "2021-08-02T09:14:48.890202",
     "exception": false,
     "start_time": "2021-08-02T09:14:48.751031",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ChestXRayDataset(Dataset):\n",
    "    def __init__(\n",
    "        self, df, data_root, transforms=None, output_label=True\n",
    "    ):\n",
    "        \n",
    "        super().__init__()\n",
    "        self.df = df.reset_index(drop=True).copy()\n",
    "        self.transforms = transforms\n",
    "        self.data_root = data_root\n",
    "        self.output_label = output_label\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.df.shape[0]\n",
    "    \n",
    "    def __getitem__(self, index: int):\n",
    "        \n",
    "        # get labels\n",
    "        if self.output_label:\n",
    "            target = self.df.iloc[index]['target']\n",
    "        \n",
    "        study_id = self.df.loc[index]['image_id']\n",
    "        image_path = \"{}/{}.png\".format(self.data_root, study_id)\n",
    "        if (image_path.find('.png') == -1):\n",
    "            image_path = image_path + '.png'\n",
    "        \n",
    "        img = get_img(image_path)\n",
    "        \n",
    "        if self.transforms:\n",
    "            img = self.transforms(image=img)['image']\n",
    "            \n",
    "        # do label smoothing\n",
    "        if self.output_label == True:\n",
    "            return img, target\n",
    "        else:\n",
    "            return img"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "developmental-project",
   "metadata": {
    "papermill": {
     "duration": 0.156759,
     "end_time": "2021-08-02T09:14:49.227556",
     "exception": false,
     "start_time": "2021-08-02T09:14:49.070797",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Define Train\\Validation Image Augmentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "personalized-ultimate",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-02T09:14:49.491053Z",
     "iopub.status.busy": "2021-08-02T09:14:49.490453Z",
     "iopub.status.idle": "2021-08-02T09:14:50.082269Z",
     "shell.execute_reply": "2021-08-02T09:14:50.081700Z",
     "shell.execute_reply.started": "2021-08-01T23:14:35.277401Z"
    },
    "papermill": {
     "duration": 0.706444,
     "end_time": "2021-08-02T09:14:50.082475",
     "exception": false,
     "start_time": "2021-08-02T09:14:49.376031",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from albumentations import (\n",
    "    HorizontalFlip, VerticalFlip, IAAPerspective, ShiftScaleRotate, CLAHE, RandomRotate90,\n",
    "    Transpose, ShiftScaleRotate, Blur, OpticalDistortion, GridDistortion, HueSaturationValue,\n",
    "    IAAAdditiveGaussianNoise, GaussNoise, MotionBlur, MedianBlur, IAAPiecewiseAffine, RandomResizedCrop,\n",
    "    IAASharpen, IAAEmboss, RandomBrightnessContrast, Flip, OneOf, Compose, Normalize, Cutout, CoarseDropout, ShiftScaleRotate, CenterCrop, Resize\n",
    ")\n",
    "\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "def get_train_transforms():\n",
    "    return Compose([\n",
    "            RandomResizedCrop(CFG['img_size'], CFG['img_size']),\n",
    "            Transpose(p=0.5),\n",
    "            HorizontalFlip(p=0.5),\n",
    "            #VerticalFlip(p=0.5),\n",
    "            ShiftScaleRotate(p=0.5),\n",
    "            HueSaturationValue(hue_shift_limit=0.2, sat_shift_limit=0.2, val_shift_limit=0.2, p=0.5),\n",
    "            RandomBrightnessContrast(brightness_limit=(-0.1,0.1), contrast_limit=(-0.1, 0.1), p=0.5),\n",
    "            Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], max_pixel_value=255.0, p=1.0),\n",
    "            #CoarseDropout(p=0.5),\n",
    "            #Cutout(p=0.5),\n",
    "            ToTensorV2(p=1.0),\n",
    "        ], p=1.)\n",
    "  \n",
    "        \n",
    "def get_valid_transforms():\n",
    "    return Compose([\n",
    "            CenterCrop(CFG['img_size'], CFG['img_size'], p=1.),\n",
    "            Resize(CFG['img_size'], CFG['img_size']),\n",
    "            Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], max_pixel_value=255.0, p=1.0),\n",
    "            ToTensorV2(p=1.0),\n",
    "        ], p=1.)\n",
    "\n",
    "def get_inference_transforms():\n",
    "    return Compose([\n",
    "            RandomResizedCrop(CFG['img_size'], CFG['img_size'], scale=(0.8, 1.0)),\n",
    "            Transpose(p=0.5),\n",
    "            HorizontalFlip(p=0.5),\n",
    "            HueSaturationValue(hue_shift_limit=0.2, sat_shift_limit=0.2, val_shift_limit=0.2, p=0.5),\n",
    "            RandomBrightnessContrast(brightness_limit=(-0.1,0.1), contrast_limit=(-0.1, 0.1), p=0.5),\n",
    "            Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], max_pixel_value=255.0, p=1.0),\n",
    "            ToTensorV2(p=1.0),\n",
    "        ], p=1.)\n",
    "\n",
    "# def get_inference_transforms():\n",
    "#     return Compose([\n",
    "#             Resize(CFG['img_size'], CFG['img_size']),\n",
    "#             Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], max_pixel_value=255.0, p=1.0),\n",
    "#             ToTensorV2(p=1.0),\n",
    "#         ], p=1.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "disturbed-leeds",
   "metadata": {
    "papermill": {
     "duration": 0.088561,
     "end_time": "2021-08-02T09:14:50.258266",
     "exception": false,
     "start_time": "2021-08-02T09:14:50.169705",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "crazy-caribbean",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-02T09:14:50.446643Z",
     "iopub.status.busy": "2021-08-02T09:14:50.446062Z",
     "iopub.status.idle": "2021-08-02T09:14:50.449787Z",
     "shell.execute_reply": "2021-08-02T09:14:50.449369Z",
     "shell.execute_reply.started": "2021-08-01T23:14:35.863167Z"
    },
    "papermill": {
     "duration": 0.101264,
     "end_time": "2021-08-02T09:14:50.449903",
     "exception": false,
     "start_time": "2021-08-02T09:14:50.348639",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ChestXrayImgClassifier(nn.Module):\n",
    "    def __init__(self, model_arch, n_class, pretrained=False):\n",
    "        super().__init__()\n",
    "        # tf_efficientnet_b6_ns\n",
    "        self.model = timm.create_model(model_arch, pretrained=pretrained, drop_rate=0.5, drop_path_rate=0.2)\n",
    "        n_features = self.model.classifier.in_features\n",
    "        self.model.classifier = nn.Sequential(\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(n_features, n_class, bias=True)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "macro-logistics",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-02T09:14:50.636542Z",
     "iopub.status.busy": "2021-08-02T09:14:50.635919Z",
     "iopub.status.idle": "2021-08-02T09:14:50.639745Z",
     "shell.execute_reply": "2021-08-02T09:14:50.639298Z",
     "shell.execute_reply.started": "2021-08-01T23:14:35.873753Z"
    },
    "papermill": {
     "duration": 0.100095,
     "end_time": "2021-08-02T09:14:50.639855",
     "exception": false,
     "start_time": "2021-08-02T09:14:50.539760",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ChestXrayImgClassifierVIT(nn.Module):\n",
    "    def __init__(self, model_arch, n_class, pretrained=False):\n",
    "        super().__init__()\n",
    "        # vit_base_patch16\n",
    "        self.model = timm.create_model(model_arch, pretrained=pretrained, img_size=640)\n",
    "        n_features = self.model.head.in_features\n",
    "        self.model.head = nn.Sequential(\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(n_features, n_class, bias=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "standing-envelope",
   "metadata": {
    "papermill": {
     "duration": 0.087621,
     "end_time": "2021-08-02T09:14:50.818231",
     "exception": false,
     "start_time": "2021-08-02T09:14:50.730610",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Main Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "coated-integration",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-02T09:14:51.015305Z",
     "iopub.status.busy": "2021-08-02T09:14:51.012255Z",
     "iopub.status.idle": "2021-08-02T09:14:51.017638Z",
     "shell.execute_reply": "2021-08-02T09:14:51.018072Z",
     "shell.execute_reply.started": "2021-08-01T23:14:35.898274Z"
    },
    "papermill": {
     "duration": 0.112911,
     "end_time": "2021-08-02T09:14:51.018226",
     "exception": false,
     "start_time": "2021-08-02T09:14:50.905315",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "\n",
    "if fast_sub:\n",
    "    df = fast_df.copy()\n",
    "else:\n",
    "    df = pd.read_csv('../input/siim-covid19-detection/sample_submission.csv')\n",
    "id_laststr_list  = []\n",
    "for i in range(df.shape[0]):\n",
    "    id_laststr_list.append(df.loc[i,'id'][-1])\n",
    "df['id_last_str'] = id_laststr_list\n",
    "\n",
    "study_len = df[df['id_last_str'] == 'y'].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "spread-bathroom",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-02T09:14:51.207447Z",
     "iopub.status.busy": "2021-08-02T09:14:51.206873Z",
     "iopub.status.idle": "2021-08-02T09:14:51.216821Z",
     "shell.execute_reply": "2021-08-02T09:14:51.216403Z",
     "shell.execute_reply.started": "2021-08-01T23:14:35.916992Z"
    },
    "papermill": {
     "duration": 0.109059,
     "end_time": "2021-08-02T09:14:51.216944",
     "exception": false,
     "start_time": "2021-08-02T09:14:51.107885",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>PredictionString</th>\n",
       "      <th>id_last_str</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00086460a852_study</td>\n",
       "      <td>negative 1 0 0 1 1</td>\n",
       "      <td>y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000c9c05fd14_study</td>\n",
       "      <td>negative 1 0 0 1 1</td>\n",
       "      <td>y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>65761e66de9f_image</td>\n",
       "      <td>none 1 0 0 1 1</td>\n",
       "      <td>e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>51759b5579bc_image</td>\n",
       "      <td>none 1 0 0 1 1</td>\n",
       "      <td>e</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   id    PredictionString id_last_str\n",
       "0  00086460a852_study  negative 1 0 0 1 1           y\n",
       "1  000c9c05fd14_study  negative 1 0 0 1 1           y\n",
       "2  65761e66de9f_image      none 1 0 0 1 1           e\n",
       "3  51759b5579bc_image      none 1 0 0 1 1           e"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "secret-treasurer",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-02T09:14:51.404859Z",
     "iopub.status.busy": "2021-08-02T09:14:51.404163Z",
     "iopub.status.idle": "2021-08-02T09:14:51.407541Z",
     "shell.execute_reply": "2021-08-02T09:14:51.407063Z",
     "shell.execute_reply.started": "2021-08-01T23:14:35.935813Z"
    },
    "papermill": {
     "duration": 0.09972,
     "end_time": "2021-08-02T09:14:51.407654",
     "exception": false,
     "start_time": "2021-08-02T09:14:51.307934",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['00086460a852_study', '000c9c05fd14_study'], dtype=object)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study_lst = df[df['id_last_str'] == 'y']['id'].values\n",
    "study_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bored-rating",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-02T09:14:51.595796Z",
     "iopub.status.busy": "2021-08-02T09:14:51.594955Z",
     "iopub.status.idle": "2021-08-02T09:14:51.597124Z",
     "shell.execute_reply": "2021-08-02T09:14:51.597602Z",
     "shell.execute_reply.started": "2021-08-01T23:14:35.943774Z"
    },
    "papermill": {
     "duration": 0.099679,
     "end_time": "2021-08-02T09:14:51.597743",
     "exception": false,
     "start_time": "2021-08-02T09:14:51.498064",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def inference_one_epoch(model, data_loader, device):\n",
    "    model.eval()\n",
    "\n",
    "    image_preds_all = []\n",
    "    \n",
    "    pbar = tqdm(enumerate(data_loader), total=len(data_loader))\n",
    "    for step, (imgs) in pbar:\n",
    "        imgs = imgs.to(device).float()\n",
    "        \n",
    "        image_preds = model(imgs)   #output = model(input)\n",
    "        image_preds_all += [torch.softmax(image_preds, 1).detach().cpu().numpy()]\n",
    "        \n",
    "    \n",
    "    image_preds_all = np.concatenate(image_preds_all, axis=0)\n",
    "    return image_preds_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "regulation-cassette",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-02T09:14:51.788896Z",
     "iopub.status.busy": "2021-08-02T09:14:51.788084Z",
     "iopub.status.idle": "2021-08-02T09:15:20.724385Z",
     "shell.execute_reply": "2021-08-02T09:15:20.724883Z",
     "shell.execute_reply.started": "2021-08-01T23:14:35.953434Z"
    },
    "papermill": {
     "duration": 29.036205,
     "end_time": "2021-08-02T09:15:20.725034",
     "exception": false,
     "start_time": "2021-08-02T09:14:51.688829",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference fold 0 started\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:03<00:00,  3.77s/it]\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.35it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.72it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.32it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.35it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.38it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.63it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.40it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.27it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.28it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.50it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.40it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.57it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.48it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.34it/s]\n"
     ]
    }
   ],
   "source": [
    "fold = 0\n",
    "test_dataset_dir = f'/kaggle/tmp/{split}/study'\n",
    " # for training only, need nightly build pytorch\n",
    "\n",
    "seed_everything(CFG['seed'])\n",
    "\n",
    "print('Inference fold {} started'.format(fold))\n",
    "\n",
    "test = pd.DataFrame()\n",
    "test['image_id'] = study_lst\n",
    "test_ds = ChestXRayDataset(test, test_dataset_dir, transforms=get_inference_transforms(), output_label=False)\n",
    "\n",
    "tst_loader = torch.utils.data.DataLoader(\n",
    "    test_ds, \n",
    "    batch_size=CFG['valid_bs'],\n",
    "    num_workers=CFG['num_workers'],\n",
    "    shuffle=False,\n",
    "    pin_memory=False,\n",
    ")\n",
    "\n",
    "device = torch.device(CFG['device'])\n",
    "model = ChestXrayImgClassifier(CFG['model_arch'], CFG['num_classes']).to(device)\n",
    "\n",
    "tst_preds = []\n",
    "\n",
    "for i, model_path in enumerate(CFG['model_paths']):\n",
    "    if i > 4:\n",
    "        break\n",
    "    model.load_state_dict(torch.load(model_path))\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for _ in range(CFG['tta']):\n",
    "            infer_one = inference_one_epoch(model, tst_loader, device)\n",
    "    #         print(infer_one)\n",
    "            tst_preds += [CFG['weights'][i]/sum(CFG['weights'])/CFG['tta']*infer_one]\n",
    "\n",
    "# print('tst_preds')\n",
    "# print(tst_preds[:10])\n",
    "# print(len(tst_preds))\n",
    "# tst_preds = np.sum(tst_preds, axis=0)\n",
    "# print(tst_preds[:10])\n",
    "# print(len(tst_preds))\n",
    "\n",
    "del model\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "organized-plaintiff",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-02T09:15:20.934215Z",
     "iopub.status.busy": "2021-08-02T09:15:20.933515Z",
     "iopub.status.idle": "2021-08-02T09:15:44.207825Z",
     "shell.execute_reply": "2021-08-02T09:15:44.208977Z",
     "shell.execute_reply.started": "2021-08-01T23:15:06.189139Z"
    },
    "papermill": {
     "duration": 23.382242,
     "end_time": "2021-08-02T09:15:44.209203",
     "exception": false,
     "start_time": "2021-08-02T09:15:20.826961",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  2.87it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.16it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.24it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.23it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.18it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.19it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.28it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.23it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.26it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.33it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.23it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.22it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.31it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.15it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.46it/s]\n"
     ]
    }
   ],
   "source": [
    "model_vit = ChestXrayImgClassifierVIT(CFG['vit_model_arch'], CFG['num_classes']).to(device)\n",
    "VIT_model_paths = CFG['model_paths'][5:]\n",
    "\n",
    "for i, model_path in enumerate(VIT_model_paths):\n",
    "    model_vit.load_state_dict(torch.load(model_path))\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for _ in range(CFG['tta']):\n",
    "            infer_one = inference_one_epoch(model_vit, tst_loader, device)\n",
    "    #         print(infer_one)\n",
    "            tst_preds += [CFG['weights'][i+5]/sum(CFG['weights'])/CFG['tta']*infer_one]\n",
    "\n",
    "tst_preds = np.sum(tst_preds, axis=0)\n",
    "del model_vit\n",
    "torch.cuda.empty_cache() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "interracial-brooks",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-02T09:15:44.553654Z",
     "iopub.status.busy": "2021-08-02T09:15:44.552803Z",
     "iopub.status.idle": "2021-08-02T09:15:44.555874Z",
     "shell.execute_reply": "2021-08-02T09:15:44.556534Z",
     "shell.execute_reply.started": "2021-08-01T23:15:28.884402Z"
    },
    "papermill": {
     "duration": 0.131291,
     "end_time": "2021-08-02T09:15:44.556749",
     "exception": false,
     "start_time": "2021-08-02T09:15:44.425458",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "print(len(tst_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "written-leonard",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-02T09:15:44.810880Z",
     "iopub.status.busy": "2021-08-02T09:15:44.809547Z",
     "iopub.status.idle": "2021-08-02T09:15:44.813654Z",
     "shell.execute_reply": "2021-08-02T09:15:44.814177Z",
     "shell.execute_reply.started": "2021-08-01T23:15:28.893234Z"
    },
    "papermill": {
     "duration": 0.134504,
     "end_time": "2021-08-02T09:15:44.814361",
     "exception": false,
     "start_time": "2021-08-02T09:15:44.679857",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.1119146 , 0.22203572, 0.42803884, 0.2380108 ],\n",
       "       [0.04202302, 0.05283254, 0.03080076, 0.87434375]], dtype=float32)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tst_preds[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "destroyed-cartridge",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-02T09:15:45.087176Z",
     "iopub.status.busy": "2021-08-02T09:15:45.086488Z",
     "iopub.status.idle": "2021-08-02T09:15:45.092637Z",
     "shell.execute_reply": "2021-08-02T09:15:45.092216Z",
     "shell.execute_reply.started": "2021-08-01T23:15:28.904428Z"
    },
    "papermill": {
     "duration": 0.145503,
     "end_time": "2021-08-02T09:15:45.092753",
     "exception": false,
     "start_time": "2021-08-02T09:15:44.947250",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00086460a852_study</td>\n",
       "      <td>0.111915</td>\n",
       "      <td>0.222036</td>\n",
       "      <td>0.428039</td>\n",
       "      <td>0.238011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000c9c05fd14_study</td>\n",
       "      <td>0.042023</td>\n",
       "      <td>0.052833</td>\n",
       "      <td>0.030801</td>\n",
       "      <td>0.874344</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             image_id         0         1         2         3\n",
       "0  00086460a852_study  0.111915  0.222036  0.428039  0.238011\n",
       "1  000c9c05fd14_study  0.042023  0.052833  0.030801  0.874344"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "debug = False\n",
    "class_labels = ['0', '1', '2', '3']\n",
    "\n",
    "test.loc[:99 if debug else test.shape[0], class_labels] = tst_preds\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "southern-drive",
   "metadata": {
    "papermill": {
     "duration": 0.124659,
     "end_time": "2021-08-02T09:15:45.350256",
     "exception": false,
     "start_time": "2021-08-02T09:15:45.225597",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# study string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "electric-large",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-02T09:15:45.605627Z",
     "iopub.status.busy": "2021-08-02T09:15:45.603829Z",
     "iopub.status.idle": "2021-08-02T09:15:45.617018Z",
     "shell.execute_reply": "2021-08-02T09:15:45.616597Z",
     "shell.execute_reply.started": "2021-08-01T23:15:28.927669Z"
    },
    "papermill": {
     "duration": 0.140687,
     "end_time": "2021-08-02T09:15:45.617127",
     "exception": false,
     "start_time": "2021-08-02T09:15:45.476440",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "name2label = { \n",
    "    'negative': 0,\n",
    "    'indeterminate': 1,\n",
    "    'typical': 2,\n",
    "    'atypical': 3}\n",
    "label2name  = {v:k for k, v in name2label.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "multiple-newspaper",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-02T09:15:45.913546Z",
     "iopub.status.busy": "2021-08-02T09:15:45.912082Z",
     "iopub.status.idle": "2021-08-02T09:15:45.914354Z",
     "shell.execute_reply": "2021-08-02T09:15:45.914762Z",
     "shell.execute_reply.started": "2021-08-01T23:15:28.935399Z"
    },
    "papermill": {
     "duration": 0.175121,
     "end_time": "2021-08-02T09:15:45.914907",
     "exception": false,
     "start_time": "2021-08-02T09:15:45.739786",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_PredictionString(row, thr=0):\n",
    "    string = ''\n",
    "    for idx in range(4):\n",
    "        conf =  row[str(idx)]\n",
    "        if conf>thr:\n",
    "            string+=f'{label2name[idx]} {conf:0.3f} 0 0 1 1 '\n",
    "    string = string.strip()\n",
    "    return string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ruled-institute",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-02T09:15:46.165785Z",
     "iopub.status.busy": "2021-08-02T09:15:46.165152Z",
     "iopub.status.idle": "2021-08-02T09:15:46.179674Z",
     "shell.execute_reply": "2021-08-02T09:15:46.179183Z",
     "shell.execute_reply.started": "2021-08-01T23:15:28.947026Z"
    },
    "papermill": {
     "duration": 0.141648,
     "end_time": "2021-08-02T09:15:46.179807",
     "exception": false,
     "start_time": "2021-08-02T09:15:46.038159",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>PredictionString</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00086460a852_study</td>\n",
       "      <td>negative 0.112 0 0 1 1 indeterminate 0.222 0 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000c9c05fd14_study</td>\n",
       "      <td>negative 0.042 0 0 1 1 indeterminate 0.053 0 0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   id                                   PredictionString\n",
       "0  00086460a852_study  negative 0.112 0 0 1 1 indeterminate 0.222 0 0...\n",
       "1  000c9c05fd14_study  negative 0.042 0 0 1 1 indeterminate 0.053 0 0..."
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['PredictionString'] = test.apply(get_PredictionString, axis=1)\n",
    "test = test.drop(class_labels, axis=1)\n",
    "test.rename(columns={'image_id':'id'}, inplace=True)\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cellular-questionnaire",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-02T09:15:46.441474Z",
     "iopub.status.busy": "2021-08-02T09:15:46.440548Z",
     "iopub.status.idle": "2021-08-02T09:15:46.444897Z",
     "shell.execute_reply": "2021-08-02T09:15:46.444463Z",
     "shell.execute_reply.started": "2021-08-01T23:15:28.973038Z"
    },
    "papermill": {
     "duration": 0.138102,
     "end_time": "2021-08-02T09:15:46.445007",
     "exception": false,
     "start_time": "2021-08-02T09:15:46.306905",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>PredictionString</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00086460a852_study</td>\n",
       "      <td>negative 0.112 0 0 1 1 indeterminate 0.222 0 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000c9c05fd14_study</td>\n",
       "      <td>negative 0.042 0 0 1 1 indeterminate 0.053 0 0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   id                                   PredictionString\n",
       "0  00086460a852_study  negative 0.112 0 0 1 1 indeterminate 0.222 0 0...\n",
       "1  000c9c05fd14_study  negative 0.042 0 0 1 1 indeterminate 0.053 0 0..."
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_study = test\n",
    "df_study"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lonely-ridge",
   "metadata": {
    "papermill": {
     "duration": 0.122885,
     "end_time": "2021-08-02T09:15:46.691214",
     "exception": false,
     "start_time": "2021-08-02T09:15:46.568329",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 2 class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fiscal-applicant",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-02T09:15:46.949476Z",
     "iopub.status.busy": "2021-08-02T09:15:46.948500Z",
     "iopub.status.idle": "2021-08-02T09:15:46.951551Z",
     "shell.execute_reply": "2021-08-02T09:15:46.951015Z",
     "shell.execute_reply.started": "2021-08-01T23:15:28.987145Z"
    },
    "papermill": {
     "duration": 0.134468,
     "end_time": "2021-08-02T09:15:46.951681",
     "exception": false,
     "start_time": "2021-08-02T09:15:46.817213",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "package_paths = [\n",
    "    '../input/pytorchimagemodels/pytorch-image-models-master', #'../input/efficientnet-pytorch-07/efficientnet_pytorch-0.7.0'\n",
    "#     '../input/image-fmix/FMix-master'\n",
    "]\n",
    "import sys; \n",
    "\n",
    "for pth in package_paths:\n",
    "    sys.path.append(pth)\n",
    "    \n",
    "# from fmix import sample_mask, make_low_freq_image, binarise_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "prerequisite-algorithm",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-02T09:15:47.210080Z",
     "iopub.status.busy": "2021-08-02T09:15:47.208825Z",
     "iopub.status.idle": "2021-08-02T09:15:47.211000Z",
     "shell.execute_reply": "2021-08-02T09:15:47.211495Z",
     "shell.execute_reply.started": "2021-08-01T23:15:28.996325Z"
    },
    "papermill": {
     "duration": 0.135805,
     "end_time": "2021-08-02T09:15:47.211627",
     "exception": false,
     "start_time": "2021-08-02T09:15:47.075822",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "from sklearn.model_selection import GroupKFold, StratifiedKFold\n",
    "import cv2\n",
    "from skimage import io\n",
    "import torch\n",
    "from torch import nn\n",
    "import os\n",
    "from datetime import datetime\n",
    "import time\n",
    "import random\n",
    "import cv2\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "from torch.utils.data.sampler import SequentialSampler, RandomSampler\n",
    "from  torch.cuda.amp import autocast, GradScaler\n",
    "\n",
    "import sklearn\n",
    "import warnings\n",
    "import joblib\n",
    "from sklearn.metrics import roc_auc_score, log_loss\n",
    "from sklearn import metrics\n",
    "import warnings\n",
    "import cv2\n",
    "import pydicom\n",
    "import timm #from efficientnet_pytorch import EfficientNet\n",
    "from scipy.ndimage.interpolation import zoom\n",
    "from sklearn.metrics import log_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "floral-limitation",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-02T09:15:47.466223Z",
     "iopub.status.busy": "2021-08-02T09:15:47.465464Z",
     "iopub.status.idle": "2021-08-02T09:15:47.468665Z",
     "shell.execute_reply": "2021-08-02T09:15:47.469098Z",
     "shell.execute_reply.started": "2021-08-01T23:15:29.00851Z"
    },
    "papermill": {
     "duration": 0.135045,
     "end_time": "2021-08-02T09:15:47.469249",
     "exception": false,
     "start_time": "2021-08-02T09:15:47.334204",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "CFG = {\n",
    "    'fold_num': 5,\n",
    "    'seed': 2021,\n",
    "    'model_arch': 'tf_efficientnetv2_m_in21k',\n",
    "    'vit_model_arch': 'vit_deit_base_patch16_384',\n",
    "    'img_size': 640,\n",
    "    'epochs': 10,\n",
    "    'train_bs': 32,\n",
    "    'valid_bs': 32,\n",
    "    'lr': 1e-4,\n",
    "    'num_workers': 4,\n",
    "    'accum_iter': 1, # suppoprt to do batch accumulation for backprop with effectively larger batch size\n",
    "    'verbose_step': 1,\n",
    "    'device': 'cuda:0',\n",
    "    'tta': 3,\n",
    "    'model_paths': ['../input/siimcovid192classes-classifier/tf_efficientnetv2_m_in21k_fold0_epoch1_colab_v1.pt',\n",
    "                   '../input/siimcovid192classes-classifier/tf_efficientnetv2_m_in21k_fold1_epoch20_colab_v2.pt',\n",
    "                   '../input/siimcovid192classes-classifier/tf_efficientnetv2_m_in21k_fold2_epoch14_colab_v3.pt',\n",
    "                   '../input/siimcovid192classes-classifier/tf_efficientnetv2_m_in21k_fold3_epoch13_colab_v4.pt',\n",
    "                   '../input/siimcovid192classes-classifier/tf_efficientnetv2_m_in21k_fold4_epoch5_colab_v5.pt',\n",
    "                   '../input/siimcovid192classes-classifier/vit_deit_base_patch16_384_fold0_epoch8_colab_v6.pt',\n",
    "                   '../input/siimcovid192classes-classifier/vit_deit_base_patch16_384_fold1_epoch8_colab_v7.pt',\n",
    "                   '../input/siimcovid192classes-classifier/vit_deit_base_patch16_384_fold2_epoch9_colab_v8.pt'],\n",
    "    'num_classes': 2,\n",
    "    'weights': [59, 59, 59, 59, 59, 58, 58, 58]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "infectious-communication",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-02T09:15:47.728852Z",
     "iopub.status.busy": "2021-08-02T09:15:47.728113Z",
     "iopub.status.idle": "2021-08-02T09:15:47.731802Z",
     "shell.execute_reply": "2021-08-02T09:15:47.731306Z",
     "shell.execute_reply.started": "2021-08-01T23:15:29.019232Z"
    },
    "papermill": {
     "duration": 0.136917,
     "end_time": "2021-08-02T09:15:47.731941",
     "exception": false,
     "start_time": "2021-08-02T09:15:47.595024",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    \n",
    "def get_img(path):\n",
    "    im_bgr = cv2.imread(path)\n",
    "    im_rgb = im_bgr[:, :, ::-1]\n",
    "    #print(im_rgb)\n",
    "    return im_rgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "civilian-hometown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-02T09:15:48.095148Z",
     "iopub.status.busy": "2021-08-02T09:15:48.093214Z",
     "iopub.status.idle": "2021-08-02T09:15:48.114293Z",
     "shell.execute_reply": "2021-08-02T09:15:48.115422Z",
     "shell.execute_reply.started": "2021-08-01T23:15:29.030807Z"
    },
    "papermill": {
     "duration": 0.24141,
     "end_time": "2021-08-02T09:15:48.115652",
     "exception": false,
     "start_time": "2021-08-02T09:15:47.874242",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from albumentations import (\n",
    "    HorizontalFlip, VerticalFlip, IAAPerspective, ShiftScaleRotate, CLAHE, RandomRotate90,\n",
    "    Transpose, ShiftScaleRotate, Blur, OpticalDistortion, GridDistortion, HueSaturationValue,\n",
    "    IAAAdditiveGaussianNoise, GaussNoise, MotionBlur, MedianBlur, IAAPiecewiseAffine, RandomResizedCrop,\n",
    "    IAASharpen, IAAEmboss, RandomBrightnessContrast, Flip, OneOf, Compose, Normalize, Cutout, CoarseDropout, ShiftScaleRotate, CenterCrop, Resize\n",
    ")\n",
    "\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "def get_train_transforms():\n",
    "    return Compose([\n",
    "            RandomResizedCrop(CFG['img_size'], CFG['img_size']),\n",
    "            Transpose(p=0.5),\n",
    "            HorizontalFlip(p=0.5),\n",
    "            #VerticalFlip(p=0.5),\n",
    "            ShiftScaleRotate(p=0.5),\n",
    "            HueSaturationValue(hue_shift_limit=0.2, sat_shift_limit=0.2, val_shift_limit=0.2, p=0.5),\n",
    "            RandomBrightnessContrast(brightness_limit=(-0.1,0.1), contrast_limit=(-0.1, 0.1), p=0.5),\n",
    "            Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], max_pixel_value=255.0, p=1.0),\n",
    "            #CoarseDropout(p=0.5),\n",
    "            #Cutout(p=0.5),\n",
    "            ToTensorV2(p=1.0),\n",
    "        ], p=1.)\n",
    "  \n",
    "        \n",
    "def get_valid_transforms():\n",
    "    return Compose([\n",
    "            CenterCrop(CFG['img_size'], CFG['img_size'], p=1.),\n",
    "            Resize(CFG['img_size'], CFG['img_size']),\n",
    "            Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], max_pixel_value=255.0, p=1.0),\n",
    "            ToTensorV2(p=1.0),\n",
    "        ], p=1.)\n",
    "\n",
    "def get_inference_transforms():\n",
    "    return Compose([\n",
    "            RandomResizedCrop(CFG['img_size'], CFG['img_size'], scale=(0.8, 1.0)),\n",
    "            Transpose(p=0.5),\n",
    "            HorizontalFlip(p=0.5),\n",
    "            HueSaturationValue(hue_shift_limit=0.2, sat_shift_limit=0.2, val_shift_limit=0.2, p=0.5),\n",
    "            RandomBrightnessContrast(brightness_limit=(-0.1,0.1), contrast_limit=(-0.1, 0.1), p=0.5),\n",
    "            Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], max_pixel_value=255.0, p=1.0),\n",
    "            ToTensorV2(p=1.0),\n",
    "        ], p=1.)\n",
    "\n",
    "# def get_inference_transforms():\n",
    "#     return Compose([\n",
    "#             Resize(CFG['img_size'], CFG['img_size']),\n",
    "#             Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], max_pixel_value=255.0, p=1.0),\n",
    "#             ToTensorV2(p=1.0),\n",
    "#         ], p=1.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "global-gates",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-02T09:15:48.529568Z",
     "iopub.status.busy": "2021-08-02T09:15:48.528626Z",
     "iopub.status.idle": "2021-08-02T09:15:48.532603Z",
     "shell.execute_reply": "2021-08-02T09:15:48.533267Z",
     "shell.execute_reply.started": "2021-08-01T23:15:29.051523Z"
    },
    "papermill": {
     "duration": 0.221327,
     "end_time": "2021-08-02T09:15:48.533501",
     "exception": false,
     "start_time": "2021-08-02T09:15:48.312174",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ChestXrayImgClassifier(nn.Module):\n",
    "    def __init__(self, model_arch, n_class, pretrained=False):\n",
    "        super().__init__()\n",
    "        # tf_efficientnet_b6_ns\n",
    "        self.model = timm.create_model(model_arch, pretrained=pretrained, drop_rate=0.3, drop_path_rate=0.2)\n",
    "        n_features = self.model.classifier.in_features\n",
    "        self.model.classifier = nn.Sequential(\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(n_features, n_class, bias=True)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "typical-absolute",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-02T09:15:48.956256Z",
     "iopub.status.busy": "2021-08-02T09:15:48.955287Z",
     "iopub.status.idle": "2021-08-02T09:15:48.959996Z",
     "shell.execute_reply": "2021-08-02T09:15:48.960575Z",
     "shell.execute_reply.started": "2021-08-01T23:15:29.064487Z"
    },
    "papermill": {
     "duration": 0.22152,
     "end_time": "2021-08-02T09:15:48.960763",
     "exception": false,
     "start_time": "2021-08-02T09:15:48.739243",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def inference_one_epoch(model, data_loader, device):\n",
    "    model.eval()\n",
    "\n",
    "    image_preds_all = []\n",
    "    \n",
    "    pbar = tqdm(enumerate(data_loader), total=len(data_loader))\n",
    "    for step, (imgs) in pbar:\n",
    "        imgs = imgs.to(device).float()\n",
    "        \n",
    "        image_preds = model(imgs)   #output = model(input)\n",
    "        image_preds_all += [torch.softmax(image_preds, 1).detach().cpu().numpy()]\n",
    "        \n",
    "    \n",
    "    image_preds_all = np.concatenate(image_preds_all, axis=0)\n",
    "    return image_preds_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ready-thesaurus",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-02T09:15:49.292725Z",
     "iopub.status.busy": "2021-08-02T09:15:49.291790Z",
     "iopub.status.idle": "2021-08-02T09:15:49.294305Z",
     "shell.execute_reply": "2021-08-02T09:15:49.293900Z",
     "shell.execute_reply.started": "2021-08-01T23:15:29.074445Z"
    },
    "papermill": {
     "duration": 0.135938,
     "end_time": "2021-08-02T09:15:49.294435",
     "exception": false,
     "start_time": "2021-08-02T09:15:49.158497",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ChestXRayDataset(Dataset):\n",
    "    def __init__(\n",
    "        self, df, data_root, transforms=None, output_label=True\n",
    "    ):\n",
    "        \n",
    "        super().__init__()\n",
    "        self.df = df.reset_index(drop=True).copy()\n",
    "        self.transforms = transforms\n",
    "        self.data_root = data_root\n",
    "        self.output_label = output_label\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.df.shape[0]\n",
    "    \n",
    "    def __getitem__(self, index: int):\n",
    "        \n",
    "        # get labels\n",
    "        if self.output_label:\n",
    "            target = self.df.iloc[index]['target']\n",
    "        \n",
    "        image_id = self.df.loc[index]['id']\n",
    "        image_path = \"{}/{}\".format(self.data_root, image_id)\n",
    "        if (image_path.find('.png') == -1):\n",
    "            image_path = image_path + '.png'\n",
    "        img = get_img(image_path)\n",
    "        \n",
    "        if self.transforms:\n",
    "            img = self.transforms(image=img)['image']\n",
    "            \n",
    "        # do label smoothing\n",
    "        if self.output_label == True:\n",
    "            return img, target\n",
    "        else:\n",
    "            return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "stable-interview",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-02T09:15:49.549048Z",
     "iopub.status.busy": "2021-08-02T09:15:49.548142Z",
     "iopub.status.idle": "2021-08-02T09:15:49.573566Z",
     "shell.execute_reply": "2021-08-02T09:15:49.574020Z",
     "shell.execute_reply.started": "2021-08-01T23:15:29.088392Z"
    },
    "papermill": {
     "duration": 0.155207,
     "end_time": "2021-08-02T09:15:49.574189",
     "exception": false,
     "start_time": "2021-08-02T09:15:49.418982",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>PredictionString</th>\n",
       "      <th>none</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>65761e66de9f_image</td>\n",
       "      <td>none 1 0 0 1 1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>51759b5579bc_image</td>\n",
       "      <td>none 1 0 0 1 1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   id PredictionString  none\n",
       "2  65761e66de9f_image   none 1 0 0 1 1     0\n",
       "3  51759b5579bc_image   none 1 0 0 1 1     0"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if fast_sub:\n",
    "    sub_df = fast_df.copy()\n",
    "else:\n",
    "    sub_df = pd.read_csv('../input/siim-covid19-detection/sample_submission.csv')\n",
    "sub_df = sub_df[study_len:]\n",
    "test_paths = f'/kaggle/tmp/{split}/image/' + sub_df['id'] +'.png'\n",
    "sub_df['none'] = 0\n",
    "sub_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "periodic-tragedy",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-02T09:15:49.835457Z",
     "iopub.status.busy": "2021-08-02T09:15:49.832679Z",
     "iopub.status.idle": "2021-08-02T09:16:12.017905Z",
     "shell.execute_reply": "2021-08-02T09:16:12.018275Z",
     "shell.execute_reply.started": "2021-08-01T23:15:29.118316Z"
    },
    "papermill": {
     "duration": 22.31763,
     "end_time": "2021-08-02T09:16:12.018459",
     "exception": false,
     "start_time": "2021-08-02T09:15:49.700829",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference fold 0 started\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  4.15it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.27it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.06it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.47it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.17it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.10it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.42it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.24it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.12it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.26it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.19it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.36it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.35it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.32it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.52it/s]\n"
     ]
    }
   ],
   "source": [
    "fold = 0\n",
    "test_dataset_dir = f'/kaggle/tmp/{split}/image'\n",
    " # for training only, need nightly build pytorch\n",
    "\n",
    "seed_everything(CFG['seed'])\n",
    "\n",
    "print('Inference fold {} started'.format(fold))\n",
    "\n",
    "test = pd.DataFrame()\n",
    "test_ds = ChestXRayDataset(sub_df, test_dataset_dir, transforms=get_inference_transforms(), output_label=False)\n",
    "\n",
    "tst_loader = torch.utils.data.DataLoader(\n",
    "    test_ds, \n",
    "    batch_size=CFG['valid_bs'],\n",
    "    num_workers=CFG['num_workers'],\n",
    "    shuffle=False,\n",
    "    pin_memory=False,\n",
    ")\n",
    "\n",
    "device = torch.device(CFG['device'])\n",
    "model = ChestXrayImgClassifier(CFG['model_arch'], CFG['num_classes']).to(device)\n",
    "\n",
    "tst_preds = []\n",
    "\n",
    "for i, model_path in enumerate(CFG['model_paths']): \n",
    "    if i > 4:\n",
    "        break\n",
    "    model.load_state_dict(torch.load(model_path))\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for _ in range(CFG['tta']):\n",
    "            infer_one = inference_one_epoch(model, tst_loader, device)\n",
    "    #         print(infer_one)\n",
    "            tst_preds += [CFG['weights'][i]/sum(CFG['weights'])/CFG['tta']*infer_one]\n",
    "\n",
    "# tst_preds = np.sum(tst_preds, axis=0)\n",
    "\n",
    "del model\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "found-youth",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-02T09:16:12.290421Z",
     "iopub.status.busy": "2021-08-02T09:16:12.289681Z",
     "iopub.status.idle": "2021-08-02T09:16:28.931046Z",
     "shell.execute_reply": "2021-08-02T09:16:28.931725Z",
     "shell.execute_reply.started": "2021-08-01T23:15:47.019472Z"
    },
    "papermill": {
     "duration": 16.780952,
     "end_time": "2021-08-02T09:16:28.931938",
     "exception": false,
     "start_time": "2021-08-02T09:16:12.150986",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  2.98it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.09it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.14it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.53it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.23it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.17it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.83it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.58it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.16it/s]\n"
     ]
    }
   ],
   "source": [
    "model_vit = ChestXrayImgClassifierVIT(CFG['vit_model_arch'], CFG['num_classes']).to(device)\n",
    "VIT_model_paths = CFG['model_paths'][5:]\n",
    "\n",
    "for i, model_path in enumerate(VIT_model_paths):\n",
    "    model_vit.load_state_dict(torch.load(model_path))\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for _ in range(CFG['tta']):\n",
    "            infer_one = inference_one_epoch(model_vit, tst_loader, device)\n",
    "    #         print(infer_one)\n",
    "            tst_preds += [CFG['weights'][i+5]/sum(CFG['weights'])/CFG['tta']*infer_one]\n",
    "\n",
    "tst_preds = np.sum(tst_preds, axis=0)\n",
    "del model_vit\n",
    "torch.cuda.empty_cache() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "average-mandate",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-02T09:16:29.230168Z",
     "iopub.status.busy": "2021-08-02T09:16:29.229432Z",
     "iopub.status.idle": "2021-08-02T09:16:29.240746Z",
     "shell.execute_reply": "2021-08-02T09:16:29.241207Z",
     "shell.execute_reply.started": "2021-08-01T23:16:01.101417Z"
    },
    "papermill": {
     "duration": 0.163201,
     "end_time": "2021-08-02T09:16:29.241363",
     "exception": false,
     "start_time": "2021-08-02T09:16:29.078162",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.87053233, 0.12946773],\n",
       "       [0.2464764 , 0.7535236 ]], dtype=float32)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tst_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "gentle-clearance",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-02T09:16:29.542972Z",
     "iopub.status.busy": "2021-08-02T09:16:29.541575Z",
     "iopub.status.idle": "2021-08-02T09:16:29.548236Z",
     "shell.execute_reply": "2021-08-02T09:16:29.548764Z",
     "shell.execute_reply.started": "2021-08-01T23:16:01.111534Z"
    },
    "papermill": {
     "duration": 0.160834,
     "end_time": "2021-08-02T09:16:29.548925",
     "exception": false,
     "start_time": "2021-08-02T09:16:29.388091",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>PredictionString</th>\n",
       "      <th>none</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>65761e66de9f_image</td>\n",
       "      <td>none 1 0 0 1 1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>51759b5579bc_image</td>\n",
       "      <td>none 1 0 0 1 1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   id PredictionString  none\n",
       "2  65761e66de9f_image   none 1 0 0 1 1     0\n",
       "3  51759b5579bc_image   none 1 0 0 1 1     0"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "antique-sudan",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-02T09:16:29.852884Z",
     "iopub.status.busy": "2021-08-02T09:16:29.852081Z",
     "iopub.status.idle": "2021-08-02T09:16:29.855548Z",
     "shell.execute_reply": "2021-08-02T09:16:29.855943Z",
     "shell.execute_reply.started": "2021-08-01T23:16:01.125444Z"
    },
    "papermill": {
     "duration": 0.160672,
     "end_time": "2021-08-02T09:16:29.856074",
     "exception": false,
     "start_time": "2021-08-02T09:16:29.695402",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>PredictionString</th>\n",
       "      <th>none</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>65761e66de9f_image</td>\n",
       "      <td>none 1 0 0 1 1</td>\n",
       "      <td>0.129468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>51759b5579bc_image</td>\n",
       "      <td>none 1 0 0 1 1</td>\n",
       "      <td>0.753524</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   id PredictionString      none\n",
       "2  65761e66de9f_image   none 1 0 0 1 1  0.129468\n",
       "3  51759b5579bc_image   none 1 0 0 1 1  0.753524"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "debug = False\n",
    "class_labels = ['none']\n",
    "\n",
    "sub_df[class_labels] = tst_preds[:, 1]\n",
    "sub_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "breathing-saudi",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-02T09:16:30.159806Z",
     "iopub.status.busy": "2021-08-02T09:16:30.159110Z",
     "iopub.status.idle": "2021-08-02T09:16:30.162280Z",
     "shell.execute_reply": "2021-08-02T09:16:30.163219Z",
     "shell.execute_reply.started": "2021-08-01T23:16:01.141044Z"
    },
    "papermill": {
     "duration": 0.159093,
     "end_time": "2021-08-02T09:16:30.163369",
     "exception": false,
     "start_time": "2021-08-02T09:16:30.004276",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>PredictionString</th>\n",
       "      <th>none</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>65761e66de9f_image</td>\n",
       "      <td>none 1 0 0 1 1</td>\n",
       "      <td>0.129468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>51759b5579bc_image</td>\n",
       "      <td>none 1 0 0 1 1</td>\n",
       "      <td>0.753524</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   id PredictionString      none\n",
       "0  65761e66de9f_image   none 1 0 0 1 1  0.129468\n",
       "1  51759b5579bc_image   none 1 0 0 1 1  0.753524"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_2class = sub_df.reset_index(drop=True)\n",
    "df_2class.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "durable-crest",
   "metadata": {
    "papermill": {
     "duration": 0.145768,
     "end_time": "2021-08-02T09:16:30.455920",
     "exception": false,
     "start_time": "2021-08-02T09:16:30.310152",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Effdet predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "radical-interval",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-02T09:16:30.753804Z",
     "iopub.status.busy": "2021-08-02T09:16:30.753109Z",
     "iopub.status.idle": "2021-08-02T09:16:30.868898Z",
     "shell.execute_reply": "2021-08-02T09:16:30.869393Z",
     "shell.execute_reply.started": "2021-08-01T23:16:01.15594Z"
    },
    "papermill": {
     "duration": 0.267522,
     "end_time": "2021-08-02T09:16:30.869561",
     "exception": false,
     "start_time": "2021-08-02T09:16:30.602039",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "included-start",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-02T09:16:31.169049Z",
     "iopub.status.busy": "2021-08-02T09:16:31.168101Z",
     "iopub.status.idle": "2021-08-02T09:16:31.216633Z",
     "shell.execute_reply": "2021-08-02T09:16:31.215989Z",
     "shell.execute_reply.started": "2021-08-01T23:16:01.27242Z"
    },
    "papermill": {
     "duration": 0.200434,
     "end_time": "2021-08-02T09:16:31.216788",
     "exception": false,
     "start_time": "2021-08-02T09:16:31.016354",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/working\n"
     ]
    }
   ],
   "source": [
    "%cd /kaggle/working/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "random-chinese",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-02T09:16:31.514013Z",
     "iopub.status.busy": "2021-08-02T09:16:31.513208Z",
     "iopub.status.idle": "2021-08-02T09:16:31.558580Z",
     "shell.execute_reply": "2021-08-02T09:16:31.558076Z",
     "shell.execute_reply.started": "2021-08-01T23:16:01.320599Z"
    },
    "papermill": {
     "duration": 0.197936,
     "end_time": "2021-08-02T09:16:31.558710",
     "exception": false,
     "start_time": "2021-08-02T09:16:31.360774",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from ensemble_boxes import *\n",
    "import torch\n",
    "import os\n",
    "from datetime import datetime\n",
    "import time\n",
    "import random\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import albumentations as A\n",
    "import matplotlib.pyplot as plt\n",
    "from albumentations.pytorch.transforms import ToTensorV2\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "from torch.utils.data.sampler import SequentialSampler, RandomSampler\n",
    "from glob import glob\n",
    "import gc\n",
    "\n",
    "SEED = 42\n",
    "\n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "seed_everything(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "medical-jumping",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-02T09:16:31.851074Z",
     "iopub.status.busy": "2021-08-02T09:16:31.850281Z",
     "iopub.status.idle": "2021-08-02T09:16:31.899584Z",
     "shell.execute_reply": "2021-08-02T09:16:31.899124Z",
     "shell.execute_reply.started": "2021-08-01T23:16:01.369685Z"
    },
    "papermill": {
     "duration": 0.19765,
     "end_time": "2021-08-02T09:16:31.899704",
     "exception": false,
     "start_time": "2021-08-02T09:16:31.702054",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>dim0</th>\n",
       "      <th>dim1</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>65761e66de9f</td>\n",
       "      <td>2330</td>\n",
       "      <td>2783</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>51759b5579bc</td>\n",
       "      <td>3093</td>\n",
       "      <td>2850</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       image_id  dim0  dim1 split\n",
       "0  65761e66de9f  2330  2783  test\n",
       "1  51759b5579bc  3093  2850  test"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta_copy = meta.copy()\n",
    "meta_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "mysterious-second",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-02T09:16:32.195967Z",
     "iopub.status.busy": "2021-08-02T09:16:32.195179Z",
     "iopub.status.idle": "2021-08-02T09:16:32.248733Z",
     "shell.execute_reply": "2021-08-02T09:16:32.248251Z",
     "shell.execute_reply.started": "2021-08-01T23:16:01.418463Z"
    },
    "papermill": {
     "duration": 0.203792,
     "end_time": "2021-08-02T09:16:32.248862",
     "exception": false,
     "start_time": "2021-08-02T09:16:32.045070",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "meta = meta_copy.copy()\n",
    "meta = meta[meta['split'] == 'test']\n",
    "if fast_sub:\n",
    "    test_df = fast_df.copy()\n",
    "else:\n",
    "    test_df = pd.read_csv('../input/siim-covid19-detection/sample_submission.csv')\n",
    "test_df = df[study_len:].reset_index(drop=True) \n",
    "meta['image_id'] = meta['image_id'] + '_image'\n",
    "meta.columns = ['id', 'dim0', 'dim1', 'split']\n",
    "# print(test_df)\n",
    "test_df = pd.merge(test_df, meta, on = 'id', how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "living-insert",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-02T09:16:32.547729Z",
     "iopub.status.busy": "2021-08-02T09:16:32.547145Z",
     "iopub.status.idle": "2021-08-02T09:16:32.598621Z",
     "shell.execute_reply": "2021-08-02T09:16:32.598166Z",
     "shell.execute_reply.started": "2021-08-01T23:16:01.470649Z"
    },
    "papermill": {
     "duration": 0.204451,
     "end_time": "2021-08-02T09:16:32.598748",
     "exception": false,
     "start_time": "2021-08-02T09:16:32.394297",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>PredictionString</th>\n",
       "      <th>id_last_str</th>\n",
       "      <th>dim0</th>\n",
       "      <th>dim1</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>65761e66de9f_image</td>\n",
       "      <td>none 1 0 0 1 1</td>\n",
       "      <td>e</td>\n",
       "      <td>2330</td>\n",
       "      <td>2783</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>51759b5579bc_image</td>\n",
       "      <td>none 1 0 0 1 1</td>\n",
       "      <td>e</td>\n",
       "      <td>3093</td>\n",
       "      <td>2850</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   id PredictionString id_last_str  dim0  dim1 split\n",
       "0  65761e66de9f_image   none 1 0 0 1 1           e  2330  2783  test\n",
       "1  51759b5579bc_image   none 1 0 0 1 1           e  3093  2850  test"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "negative-airline",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-02T09:16:32.893207Z",
     "iopub.status.busy": "2021-08-02T09:16:32.892459Z",
     "iopub.status.idle": "2021-08-02T09:16:32.935751Z",
     "shell.execute_reply": "2021-08-02T09:16:32.935343Z",
     "shell.execute_reply.started": "2021-08-01T23:16:01.520576Z"
    },
    "papermill": {
     "duration": 0.193478,
     "end_time": "2021-08-02T09:16:32.935868",
     "exception": false,
     "start_time": "2021-08-02T09:16:32.742390",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_valid_transforms_effdet():\n",
    "    return A.Compose(\n",
    "        [\n",
    "            A.Resize(height=640, width=640, p=1.0),\n",
    "            ToTensorV2(p=1.0),\n",
    "        ], p=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "premier-surgery",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-02T09:16:33.231699Z",
     "iopub.status.busy": "2021-08-02T09:16:33.230898Z",
     "iopub.status.idle": "2021-08-02T09:16:33.275359Z",
     "shell.execute_reply": "2021-08-02T09:16:33.274912Z",
     "shell.execute_reply.started": "2021-08-01T23:16:01.563814Z"
    },
    "papermill": {
     "duration": 0.19546,
     "end_time": "2021-08-02T09:16:33.275477",
     "exception": false,
     "start_time": "2021-08-02T09:16:33.080017",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "DATA_ROOT_PATH = f'/kaggle/tmp/{split}/image/'\n",
    "\n",
    "class DatasetRetriever(Dataset):\n",
    "    def __init__(self, image_ids, transforms=None):\n",
    "        super().__init__()\n",
    "        self.image_ids = image_ids\n",
    "        self.transforms = transforms\n",
    "\n",
    "    def __getitem__(self, index: int):\n",
    "        image_id = self.image_ids[index]\n",
    "        image = cv2.imread(f'{DATA_ROOT_PATH}/{image_id}.png', cv2.IMREAD_COLOR)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB).astype(np.float32)\n",
    "        image /= 255.0\n",
    "        if self.transforms:\n",
    "            sample = {'image': image}\n",
    "            sample = self.transforms(**sample)\n",
    "            image = sample['image']\n",
    "        return image, image_id\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return self.image_ids.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "alpha-powell",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-02T09:16:33.569165Z",
     "iopub.status.busy": "2021-08-02T09:16:33.568418Z",
     "iopub.status.idle": "2021-08-02T09:16:33.612137Z",
     "shell.execute_reply": "2021-08-02T09:16:33.611726Z",
     "shell.execute_reply.started": "2021-08-01T23:16:01.611589Z"
    },
    "papermill": {
     "duration": 0.19279,
     "end_time": "2021-08-02T09:16:33.612254",
     "exception": false,
     "start_time": "2021-08-02T09:16:33.419464",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "validation_dataset = DatasetRetriever(\n",
    "    image_ids=meta[\"id\"].values,\n",
    "    transforms=get_valid_transforms_effdet()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "equal-literature",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-02T09:16:33.904883Z",
     "iopub.status.busy": "2021-08-02T09:16:33.904010Z",
     "iopub.status.idle": "2021-08-02T09:16:33.948904Z",
     "shell.execute_reply": "2021-08-02T09:16:33.948498Z",
     "shell.execute_reply.started": "2021-08-01T23:16:01.655971Z"
    },
    "papermill": {
     "duration": 0.193113,
     "end_time": "2021-08-02T09:16:33.949021",
     "exception": false,
     "start_time": "2021-08-02T09:16:33.755908",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['65761e66de9f_image', '51759b5579bc_image'], dtype=object)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_dataset.image_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "breeding-consensus",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-02T09:16:34.244308Z",
     "iopub.status.busy": "2021-08-02T09:16:34.243552Z",
     "iopub.status.idle": "2021-08-02T09:16:34.960246Z",
     "shell.execute_reply": "2021-08-02T09:16:34.959790Z",
     "shell.execute_reply.started": "2021-08-01T23:16:01.70081Z"
    },
    "papermill": {
     "duration": 0.866831,
     "end_time": "2021-08-02T09:16:34.960393",
     "exception": false,
     "start_time": "2021-08-02T09:16:34.093562",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51759b5579bc_image.png\t65761e66de9f_image.png\r\n"
     ]
    }
   ],
   "source": [
    "!ls /kaggle/tmp/test/image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "assured-reform",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-02T09:16:35.280608Z",
     "iopub.status.busy": "2021-08-02T09:16:35.279731Z",
     "iopub.status.idle": "2021-08-02T09:16:35.335783Z",
     "shell.execute_reply": "2021-08-02T09:16:35.335303Z",
     "shell.execute_reply.started": "2021-08-01T23:16:02.412252Z"
    },
    "papermill": {
     "duration": 0.229243,
     "end_time": "2021-08-02T09:16:35.335918",
     "exception": false,
     "start_time": "2021-08-02T09:16:35.106675",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "SKIP_BOX_THR = 0.001\n",
    "IMAGE_ID_TO_SIZE = {}\n",
    "for i in range(len(meta)):\n",
    "    IMAGE_ID_TO_SIZE[meta.at[i, \"id\"]] = {\"width\": meta.at[i, \"dim1\"], \"height\": meta.at[i, \"dim0\"]}\n",
    "    \n",
    "def get_boxes_classes_from_preds(preds, score_threshold=SKIP_BOX_THR):\n",
    "    det = preds\n",
    "    predictions = []\n",
    "    for i in range(len(det)):\n",
    "        boxes = det[i].detach().cpu().numpy()[:,:4]    \n",
    "        scores = det[i].detach().cpu().numpy()[:,4]\n",
    "        indexes = np.where(scores > score_threshold)[0]\n",
    "        boxes = boxes[indexes]\n",
    "        boxes[:, 2] = boxes[:, 2] + boxes[:, 0]\n",
    "        boxes[:, 3] = boxes[:, 3] + boxes[:, 1]\n",
    "        predictions.append({\n",
    "            'boxes': boxes[indexes],\n",
    "            'scores': scores[indexes],\n",
    "        })\n",
    "    return [predictions]\n",
    "\n",
    "\n",
    "def run_wbf(predictions, image_index, image_size=512, iou_thr=0.44, skip_box_thr=SKIP_BOX_THR, weights=None):\n",
    "    boxes = [(prediction[image_index]['boxes']/(image_size-1)).tolist()  for prediction in predictions]\n",
    "    scores = [prediction[image_index]['scores'].tolist()  for prediction in predictions]\n",
    "    labels = [np.ones(prediction[image_index]['scores'].shape[0]).tolist() for prediction in predictions]\n",
    "    boxes, scores, labels = weighted_boxes_fusion(boxes, scores, labels, weights=None, iou_thr=iou_thr, skip_box_thr=skip_box_thr)\n",
    "    boxes = boxes*(image_size-1)\n",
    "    return boxes, scores, labels\n",
    "\n",
    "def run_nms(predictions, image_index, image_size=640, iou_thr=0.5, weights=None):\n",
    "    boxes = [(prediction[image_index]['boxes']/(image_size-1)).tolist()  for prediction in predictions]\n",
    "    scores = [prediction[image_index]['scores'].tolist()  for prediction in predictions]\n",
    "    labels = [np.ones(prediction[image_index]['scores'].shape[0]).tolist() for prediction in predictions]\n",
    "    boxes, scores, labels = nms(boxes, scores, labels, weights=None, iou_thr=iou_thr)\n",
    "    boxes = boxes*(image_size-1)\n",
    "    return boxes, scores, labels\n",
    "\n",
    "def box_label_conf_to_pred_str(boxes, labels, confs):\n",
    "    pred_str = []\n",
    "    for i in range(len(boxes)):\n",
    "        x1, y1, x2, y2 = boxes[i]\n",
    "        pred_str.append(f\"{labels[i]} {confs[i]} {x1} {y1} {x2} {y2}\")\n",
    "    pred_str = \" \".join(pred_str)\n",
    "    return pred_str\n",
    "\n",
    "def box_to_original_size(boxes, image_id, image_id_to_size, imsize=512):\n",
    "    boxes = boxes.copy()\n",
    "    for i, box in enumerate(boxes):\n",
    "        w = image_id_to_size[image_id][\"width\"]\n",
    "        h = image_id_to_size[image_id][\"height\"]\n",
    "        box[[0,2]] = box[[0,2]] / imsize * w\n",
    "        box[[1,3]] = box[[1,3]] / imsize * h\n",
    "        boxes[i] = box\n",
    "    return boxes    \n",
    "\n",
    "class Fitter:\n",
    "    def __init__(self, model, device, config):\n",
    "        self.config = config\n",
    "\n",
    "        self.base_dir = f'./{config.folder}'\n",
    "        if not os.path.exists(self.base_dir):\n",
    "            os.makedirs(self.base_dir)\n",
    "        \n",
    "        self.log_path = f'{self.base_dir}/log.txt'\n",
    "\n",
    "        self.model = model\n",
    "        self.device = device\n",
    "\n",
    "        self.log(f'Fitter prepared. Device is {self.device}')\n",
    "\n",
    "    def infer(self, val_loader, iou_threshold, visualize=False):\n",
    "        print(\"iou threshold:\", iou_threshold)\n",
    "        self.log(f\"iou threshold: {iou_threshold}\")\n",
    "        self.model.eval()\n",
    "        t = time.time()\n",
    "        results = []\n",
    "        for step, (images, image_ids) in tqdm(enumerate(val_loader)):            \n",
    "            with torch.no_grad():\n",
    "                images = torch.stack(images)\n",
    "                batch_size = images.shape[0]\n",
    "                images = images.to(self.device).float()\n",
    "\n",
    "                pred = self.model(images, torch.tensor([1]*images.shape[0]).float().cuda())\n",
    "                \n",
    "                predictions = get_boxes_classes_from_preds(pred)\n",
    "                for i, image in enumerate(images):\n",
    "#                     boxes, scores, labels = run_wbf(predictions, image_index=i, iou_thr=iou_threshold)\n",
    "                    boxes, scores, labels = run_nms(predictions, image_index=i, iou_thr=iou_threshold)\n",
    "                    boxes = boxes.astype(np.int32).clip(min=0, max=640)\n",
    "                    image_id = image_ids[i]\n",
    "                    text_labels = [\"opacity\"] * len(boxes)\n",
    "\n",
    "                    boxes_ori_size = box_to_original_size(boxes, image_id, IMAGE_ID_TO_SIZE, imsize=640)\n",
    "                    result = {\n",
    "                        'id': image_id,\n",
    "                        'PredictionString': box_label_conf_to_pred_str(boxes_ori_size, text_labels, scores)\n",
    "                    }\n",
    "                    results.append(result)\n",
    "                    \n",
    "\n",
    "                    #visualize\n",
    "                    if visualize:\n",
    "                      if i==0 and np.random.uniform() < 0.02:\n",
    "                          sample = images[i].permute(1,2,0).cpu().numpy()\n",
    "                          sample = np.ascontiguousarray(sample)\n",
    "                    \n",
    "                          fig, ax = plt.subplots(1, 1, figsize=(16, 8))\n",
    "\n",
    "                          for score, box in zip(scores, boxes):\n",
    "                              sample[int(box[1]):int(box[3]), int(box[0]):int(box[2]), 1] += score\n",
    "\n",
    "                          for score, box in zip(scores, boxes):\n",
    "                              sample = cv2.rectangle(sample, (int(box[0]), int(box[1])), (int(box[2]), int(box[3])), (1, 0, 0, min(score*3,1)), 2)\n",
    "                              \n",
    "                          ax.set_axis_off()\n",
    "                          ax.imshow(sample)\n",
    "                          plt.show()\n",
    "                          print(result)\n",
    "        \n",
    "        result_df = pd.DataFrame(results, columns=['id', 'PredictionString'])\n",
    "        os.makedirs('/kaggle/working/effdet_results', exist_ok=True)\n",
    "        result_file = f'/kaggle/working/effdet_results/result.csv'\n",
    "        result_df.to_csv(result_file, index=False)\n",
    "        return result_df\n",
    "\n",
    "    def log(self, message):\n",
    "        if self.config.verbose:\n",
    "            print(message)\n",
    "        with open(self.log_path, 'a+') as logger:\n",
    "            logger.write(f'{message}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "respiratory-iraqi",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-02T09:16:35.632750Z",
     "iopub.status.busy": "2021-08-02T09:16:35.631988Z",
     "iopub.status.idle": "2021-08-02T09:16:35.675401Z",
     "shell.execute_reply": "2021-08-02T09:16:35.674971Z",
     "shell.execute_reply.started": "2021-08-01T23:16:02.49652Z"
    },
    "papermill": {
     "duration": 0.194218,
     "end_time": "2021-08-02T09:16:35.675525",
     "exception": false,
     "start_time": "2021-08-02T09:16:35.481307",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class TrainGlobalConfig:\n",
    "    num_workers = 2\n",
    "    batch_size = 4\n",
    "    folder = 'effdet5-cutmix-augmix'\n",
    "    verbose = True\n",
    "    verbose_step = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "editorial-tuesday",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-02T09:16:35.972697Z",
     "iopub.status.busy": "2021-08-02T09:16:35.971923Z",
     "iopub.status.idle": "2021-08-02T09:16:36.015352Z",
     "shell.execute_reply": "2021-08-02T09:16:36.014930Z",
     "shell.execute_reply.started": "2021-08-01T23:16:02.544029Z"
    },
    "papermill": {
     "duration": 0.195172,
     "end_time": "2021-08-02T09:16:36.015470",
     "exception": false,
     "start_time": "2021-08-02T09:16:35.820298",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    return tuple(zip(*batch))\n",
    "\n",
    "def run_inference():\n",
    "    device = torch.device('cuda:0')\n",
    "    net.to(device)\n",
    "\n",
    "    val_loader = torch.utils.data.DataLoader(\n",
    "        validation_dataset, \n",
    "        batch_size=TrainGlobalConfig.batch_size,\n",
    "        num_workers=TrainGlobalConfig.num_workers,\n",
    "        shuffle=False,\n",
    "        sampler=SequentialSampler(validation_dataset),\n",
    "        pin_memory=False,\n",
    "        collate_fn=collate_fn,\n",
    "    )\n",
    "\n",
    "    fitter = Fitter(model=net, device=device, config=TrainGlobalConfig)\n",
    "    result_df = fitter.infer(val_loader, iou_threshold=0.5, visualize=True)\n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "centered-apollo",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-02T09:16:36.311914Z",
     "iopub.status.busy": "2021-08-02T09:16:36.311132Z",
     "iopub.status.idle": "2021-08-02T09:16:36.602935Z",
     "shell.execute_reply": "2021-08-02T09:16:36.601910Z",
     "shell.execute_reply.started": "2021-08-01T23:16:02.591009Z"
    },
    "papermill": {
     "duration": 0.442216,
     "end_time": "2021-08-02T09:16:36.603070",
     "exception": false,
     "start_time": "2021-08-02T09:16:36.160854",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from effdet import get_efficientdet_config, EfficientDet, DetBenchTrain, DetBenchEval\n",
    "from effdet.efficientdet import HeadNet\n",
    "\n",
    "def load_net(checkpoint_path):\n",
    "    config = get_efficientdet_config('tf_efficientdet_d5')\n",
    "    net = EfficientDet(config, pretrained_backbone=False)\n",
    "\n",
    "    config.num_classes = 1\n",
    "    config.image_size=640\n",
    "    net.class_net = HeadNet(config, num_outputs=config.num_classes, norm_kwargs=dict(eps=.001, momentum=.01))\n",
    "\n",
    "    checkpoint = torch.load(checkpoint_path)\n",
    "    net.load_state_dict(checkpoint['model_state_dict'])\n",
    "\n",
    "    del checkpoint\n",
    "    gc.collect()\n",
    "\n",
    "    net = DetBenchEval(net, config)\n",
    "    net.eval();\n",
    "    return net.cuda()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "familiar-magic",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-02T09:16:36.897627Z",
     "iopub.status.busy": "2021-08-02T09:16:36.896746Z",
     "iopub.status.idle": "2021-08-02T09:16:36.992796Z",
     "shell.execute_reply": "2021-08-02T09:16:36.992275Z",
     "shell.execute_reply.started": "2021-08-01T23:16:02.826425Z"
    },
    "papermill": {
     "duration": 0.245106,
     "end_time": "2021-08-02T09:16:36.992931",
     "exception": false,
     "start_time": "2021-08-02T09:16:36.747825",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# net = load_net('/kaggle/input/siimcovid19-effdet/effdet5_640_fold0_epoch20.bin')\n",
    "# effdet_fold0 = run_inference()\n",
    "# effdet_fold0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "burning-liechtenstein",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-02T09:16:37.288846Z",
     "iopub.status.busy": "2021-08-02T09:16:37.288054Z",
     "iopub.status.idle": "2021-08-02T09:16:37.331233Z",
     "shell.execute_reply": "2021-08-02T09:16:37.331626Z",
     "shell.execute_reply.started": "2021-08-01T23:16:02.87105Z"
    },
    "papermill": {
     "duration": 0.192231,
     "end_time": "2021-08-02T09:16:37.331775",
     "exception": false,
     "start_time": "2021-08-02T09:16:37.139544",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# net = load_net('/kaggle/input/siimcovid19-effdet/effdet5_640_fold1_epoch21.bin')\n",
    "# effdet_fold1 = run_inference()\n",
    "# effdet_fold1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "robust-tradition",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-02T09:16:37.625991Z",
     "iopub.status.busy": "2021-08-02T09:16:37.625139Z",
     "iopub.status.idle": "2021-08-02T09:16:37.669094Z",
     "shell.execute_reply": "2021-08-02T09:16:37.668584Z",
     "shell.execute_reply.started": "2021-08-01T23:16:02.916396Z"
    },
    "papermill": {
     "duration": 0.192816,
     "end_time": "2021-08-02T09:16:37.669210",
     "exception": false,
     "start_time": "2021-08-02T09:16:37.476394",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# net = load_net('/kaggle/input/siimcovid19-effdet/effdet5_640_fold2_epoch24.bin')\n",
    "# effdet_fold2 = run_inference()\n",
    "# effdet_fold2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "bearing-sleeve",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-02T09:16:37.972453Z",
     "iopub.status.busy": "2021-08-02T09:16:37.971673Z",
     "iopub.status.idle": "2021-08-02T09:16:49.571162Z",
     "shell.execute_reply": "2021-08-02T09:16:49.570610Z",
     "shell.execute_reply.started": "2021-08-01T23:16:02.960995Z"
    },
    "papermill": {
     "duration": 11.750341,
     "end_time": "2021-08-02T09:16:49.571306",
     "exception": false,
     "start_time": "2021-08-02T09:16:37.820965",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitter prepared. Device is cuda:0\n",
      "iou threshold: 0.5\n",
      "iou threshold: 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning. Fixed 3 boxes coordinates < 0\n",
      "Warning. Fixed 5 boxes coordinates > 1. Check that your boxes was normalized at [0, 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:04,  4.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning. Fixed 1 boxes coordinates < 0\n",
      "Warning. Fixed 1 boxes coordinates > 1. Check that your boxes was normalized at [0, 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>PredictionString</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>65761e66de9f_image</td>\n",
       "      <td>opacity 0.38977867364883423 1817 888 2430 1521...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>51759b5579bc_image</td>\n",
       "      <td>opacity 0.4435000419616699 169 1908 1055 2479 ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   id                                   PredictionString\n",
       "0  65761e66de9f_image  opacity 0.38977867364883423 1817 888 2430 1521...\n",
       "1  51759b5579bc_image  opacity 0.4435000419616699 169 1908 1055 2479 ..."
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = load_net('/kaggle/input/siimcovid19-effdet/effdet5_640_fold3_epoch20.bin')\n",
    "effdet_fold3 = run_inference()\n",
    "effdet_fold3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "driving-invite",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-02T09:16:49.967758Z",
     "iopub.status.busy": "2021-08-02T09:16:49.966823Z",
     "iopub.status.idle": "2021-08-02T09:16:58.224589Z",
     "shell.execute_reply": "2021-08-02T09:16:58.225080Z",
     "shell.execute_reply.started": "2021-08-01T23:16:14.305013Z"
    },
    "papermill": {
     "duration": 8.495712,
     "end_time": "2021-08-02T09:16:58.225265",
     "exception": false,
     "start_time": "2021-08-02T09:16:49.729553",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitter prepared. Device is cuda:0\n",
      "iou threshold: 0.5\n",
      "iou threshold: 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00,  3.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning. Fixed 1 boxes coordinates < 0\n",
      "Warning. Fixed 1 boxes coordinates > 1. Check that your boxes was normalized at [0, 1]\n",
      "Warning. Fixed 1 boxes coordinates < 0\n",
      "Warning. Fixed 4 boxes coordinates > 1. Check that your boxes was normalized at [0, 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>PredictionString</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>65761e66de9f_image</td>\n",
       "      <td>opacity 0.40472644567489624 1839 811 2417 1518...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>51759b5579bc_image</td>\n",
       "      <td>opacity 0.42967167496681213 173 1899 1059 2498...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   id                                   PredictionString\n",
       "0  65761e66de9f_image  opacity 0.40472644567489624 1839 811 2417 1518...\n",
       "1  51759b5579bc_image  opacity 0.42967167496681213 173 1899 1059 2498..."
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = load_net('/kaggle/input/siimcovid19-effdet/effdet5_640_fold4_epoch24.bin')\n",
    "effdet_fold4 = run_inference()\n",
    "effdet_fold4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "organic-startup",
   "metadata": {
    "papermill": {
     "duration": 0.157976,
     "end_time": "2021-08-02T09:16:58.545520",
     "exception": false,
     "start_time": "2021-08-02T09:16:58.387544",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# yolov5 predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "wicked-improvement",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-02T09:16:58.866942Z",
     "iopub.status.busy": "2021-08-02T09:16:58.865824Z",
     "iopub.status.idle": "2021-08-02T09:16:58.986310Z",
     "shell.execute_reply": "2021-08-02T09:16:58.985473Z",
     "shell.execute_reply.started": "2021-08-01T23:16:22.285083Z"
    },
    "papermill": {
     "duration": 0.283536,
     "end_time": "2021-08-02T09:16:58.986484",
     "exception": false,
     "start_time": "2021-08-02T09:16:58.702948",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np, pandas as pd\n",
    "from glob import glob\n",
    "import shutil, os\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from tqdm.notebook import tqdm\n",
    "import seaborn as sns\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "cloudy-minneapolis",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-02T09:16:59.308724Z",
     "iopub.status.busy": "2021-08-02T09:16:59.308128Z",
     "iopub.status.idle": "2021-08-02T09:16:59.363393Z",
     "shell.execute_reply": "2021-08-02T09:16:59.364245Z",
     "shell.execute_reply.started": "2021-08-01T23:16:22.451511Z"
    },
    "papermill": {
     "duration": 0.21744,
     "end_time": "2021-08-02T09:16:59.364451",
     "exception": false,
     "start_time": "2021-08-02T09:16:59.147011",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>dim0</th>\n",
       "      <th>dim1</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>65761e66de9f_image</td>\n",
       "      <td>2330</td>\n",
       "      <td>2783</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>51759b5579bc_image</td>\n",
       "      <td>3093</td>\n",
       "      <td>2850</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   id  dim0  dim1 split\n",
       "0  65761e66de9f_image  2330  2783  test\n",
       "1  51759b5579bc_image  3093  2850  test"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "turkish-economy",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-02T09:16:59.686394Z",
     "iopub.status.busy": "2021-08-02T09:16:59.685568Z",
     "iopub.status.idle": "2021-08-02T09:16:59.741546Z",
     "shell.execute_reply": "2021-08-02T09:16:59.741116Z",
     "shell.execute_reply.started": "2021-08-01T23:16:22.536005Z"
    },
    "papermill": {
     "duration": 0.221461,
     "end_time": "2021-08-02T09:16:59.741669",
     "exception": false,
     "start_time": "2021-08-02T09:16:59.520208",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>PredictionString</th>\n",
       "      <th>id_last_str</th>\n",
       "      <th>dim0</th>\n",
       "      <th>dim1</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>65761e66de9f_image</td>\n",
       "      <td>none 1 0 0 1 1</td>\n",
       "      <td>e</td>\n",
       "      <td>2330</td>\n",
       "      <td>2783</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>51759b5579bc_image</td>\n",
       "      <td>none 1 0 0 1 1</td>\n",
       "      <td>e</td>\n",
       "      <td>3093</td>\n",
       "      <td>2850</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   id PredictionString id_last_str  dim0  dim1 split\n",
       "0  65761e66de9f_image   none 1 0 0 1 1           e  2330  2783  test\n",
       "1  51759b5579bc_image   none 1 0 0 1 1           e  3093  2850  test"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta = meta[meta['split'] == 'test']\n",
    "if fast_sub:\n",
    "    test_df = fast_df.copy()\n",
    "else:\n",
    "    test_df = pd.read_csv('../input/siim-covid19-detection/sample_submission.csv')\n",
    "test_df = df[study_len:].reset_index(drop=True) \n",
    "# meta['image_id'] = meta['image_id'] + '_image'\n",
    "# meta.columns = ['id', 'dim0', 'dim1', 'split']\n",
    "test_df = pd.merge(test_df, meta, on = 'id', how = 'left')\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "established-compact",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-02T09:17:00.069894Z",
     "iopub.status.busy": "2021-08-02T09:17:00.068979Z",
     "iopub.status.idle": "2021-08-02T09:17:00.478263Z",
     "shell.execute_reply": "2021-08-02T09:17:00.477772Z",
     "shell.execute_reply.started": "2021-08-01T23:16:22.634796Z"
    },
    "papermill": {
     "duration": 0.570983,
     "end_time": "2021-08-02T09:17:00.478427",
     "exception": false,
     "start_time": "2021-08-02T09:16:59.907444",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "shutil.copytree('/kaggle/input/yolov5-official-v31-dataset/yolov5', '/kaggle/working/yolov5')\n",
    "os.chdir('/kaggle/working/yolov5') # install dependencies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "intelligent-walter",
   "metadata": {
    "papermill": {
     "duration": 0.156248,
     "end_time": "2021-08-02T09:17:00.796161",
     "exception": false,
     "start_time": "2021-08-02T09:17:00.639913",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## yolov5 fold 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "visible-direction",
   "metadata": {
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2021-08-02T09:17:01.372519Z",
     "iopub.status.busy": "2021-08-02T09:17:01.371694Z",
     "iopub.status.idle": "2021-08-02T09:17:12.699993Z",
     "shell.execute_reply": "2021-08-02T09:17:12.699501Z",
     "shell.execute_reply.started": "2021-08-01T23:16:23.186062Z"
    },
    "papermill": {
     "duration": 11.625493,
     "end_time": "2021-08-02T09:17:12.700110",
     "exception": false,
     "start_time": "2021-08-02T09:17:01.074617",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(agnostic_nms=False, augment=True, classes=None, conf_thres=0.001, device='', exist_ok=False, img_size=640, iou_thres=0.5, name='exp', project='runs/detect', save_conf=True, save_txt=True, source='/kaggle/tmp/test/image', update=False, view_img=False, weights=['/kaggle/input/siimcovid19-detection-models/yolov5x_fold0_nb_v14_best.pt'])\r\n",
      "Fusing layers... \r\n",
      "image 1/2 /kaggle/tmp/test/image/51759b5579bc_image.png: 640x640 50 0. opacitys, Done. (0.164s)\r\n",
      "image 2/2 /kaggle/tmp/test/image/65761e66de9f_image.png: 640x640 41 0. opacitys, Done. (0.156s)\r\n",
      "Results saved to runs/detect/exp\r\n",
      "2 labels saved to runs/detect/exp/labels\r\n",
      "Done. (0.554s)\r\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a621e8217214eecae2b5b9eb3990355",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>PredictionString</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>51759b5579bc_image</td>\n",
       "      <td>opacity 0.001049999963 1585.0 764.0 2195.0 176...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>65761e66de9f_image</td>\n",
       "      <td>opacity 0.001011849963 2061.0 1154.0 2366.0 14...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   id                                   PredictionString\n",
       "0  51759b5579bc_image  opacity 0.001049999963 1585.0 764.0 2195.0 176...\n",
       "1  65761e66de9f_image  opacity 0.001011849963 2061.0 1154.0 2366.0 14..."
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dim = 640 #1024, 256, 'original'\n",
    "test_dir = f'/kaggle/tmp/{split}/image'\n",
    "weights_dir = '/kaggle/input/siimcovid19-detection-models/yolov5x_fold0_nb_v14_best.pt'\n",
    "\n",
    "import torch\n",
    "#from IPython.display import Image, clear_output  # to display images\n",
    "\n",
    "#clear_output()\n",
    "#print('Setup complete. Using torch %s %s' % (torch.__version__, torch.cuda.get_device_properties(0) if torch.cuda.is_available() else 'CPU'))\n",
    "\n",
    "\n",
    "!python detect.py --weights $weights_dir\\\n",
    "--img 640\\\n",
    "--conf 0.001\\\n",
    "--iou 0.5\\\n",
    "--source $test_dir\\\n",
    "--save-txt --save-conf --augment\n",
    "\n",
    "\n",
    "def yolo2voc(image_height, image_width, bboxes):\n",
    "    \"\"\"\n",
    "    yolo => [xmid, ymid, w, h] (normalized)\n",
    "    voc  => [x1, y1, x2, y1]\n",
    "\n",
    "    \"\"\" \n",
    "    bboxes = bboxes.copy().astype(float) # otherwise all value will be 0 as voc_pascal dtype is np.int\n",
    "\n",
    "    bboxes[..., [0, 2]] = bboxes[..., [0, 2]]* image_width\n",
    "    bboxes[..., [1, 3]] = bboxes[..., [1, 3]]* image_height\n",
    "\n",
    "    bboxes[..., [0, 1]] = bboxes[..., [0, 1]] - bboxes[..., [2, 3]]/2\n",
    "    bboxes[..., [2, 3]] = bboxes[..., [0, 1]] + bboxes[..., [2, 3]]\n",
    "\n",
    "    return bboxes\n",
    "\n",
    "image_ids = [] # (num_images, )\n",
    "PredictionStrings = [] # (num_images, boxes_lst)\n",
    "\n",
    "for file_path in tqdm(glob('runs/detect/exp/labels/*.txt')):\n",
    "    image_id = file_path.split('/')[-1].split('.')[0]\n",
    "    w, h = test_df.loc[test_df.id==image_id,['dim1', 'dim0']].values[0]\n",
    "    f = open(file_path, 'r')\n",
    "    data = np.array(f.read().replace('\\n', ' ').strip().split(' ')).astype(np.float32).reshape(-1, 6)\n",
    "    data = data[:, [0, 5, 1, 2, 3, 4]]\n",
    "    bboxes = list(np.round(np.concatenate((data[:, :2], np.round(yolo2voc(h, w, data[:, 2:]))), axis =1).reshape(-1), 12).astype(str))\n",
    "    new_bboxes = []\n",
    "    for idx in range(len(bboxes)):\n",
    "        if idx%6 == 0:\n",
    "            new_bboxes.append('opacity')\n",
    "        else :\n",
    "            new_bboxes.append(bboxes[idx])\n",
    "    image_ids.append(image_id)\n",
    "    PredictionStrings.append(' '.join(new_bboxes))\n",
    "\n",
    "\n",
    "pred_yolov5_fold0_df = pd.DataFrame({'id':image_ids,\n",
    "                        'PredictionString':PredictionStrings})\n",
    "pred_yolov5_fold0_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hindu-boundary",
   "metadata": {
    "papermill": {
     "duration": 0.150482,
     "end_time": "2021-08-02T09:17:13.002837",
     "exception": false,
     "start_time": "2021-08-02T09:17:12.852355",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## yolov5 fold 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "earned-receipt",
   "metadata": {
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2021-08-02T09:17:13.322064Z",
     "iopub.status.busy": "2021-08-02T09:17:13.321244Z",
     "iopub.status.idle": "2021-08-02T09:17:23.966379Z",
     "shell.execute_reply": "2021-08-02T09:17:23.966813Z",
     "shell.execute_reply.started": "2021-08-01T23:16:33.845313Z"
    },
    "papermill": {
     "duration": 10.813902,
     "end_time": "2021-08-02T09:17:23.966980",
     "exception": false,
     "start_time": "2021-08-02T09:17:13.153078",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(agnostic_nms=False, augment=True, classes=None, conf_thres=0.001, device='', exist_ok=False, img_size=640, iou_thres=0.5, name='exp', project='runs/detect', save_conf=True, save_txt=True, source='/kaggle/tmp/test/image', update=False, view_img=False, weights=['/kaggle/input/siimcovid19-detection-models/yolov5x_fold1_nb_v19_best.pt'])\r\n",
      "Fusing layers... \r\n",
      "image 1/2 /kaggle/tmp/test/image/51759b5579bc_image.png: 640x640 40 0. opacitys, Done. (0.196s)\r\n",
      "image 2/2 /kaggle/tmp/test/image/65761e66de9f_image.png: 640x640 33 0. opacitys, Done. (0.166s)\r\n",
      "Results saved to runs/detect/exp2\r\n",
      "2 labels saved to runs/detect/exp2/labels\r\n",
      "Done. (0.595s)\r\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d86bc9a21014ae08910586b94101302",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>PredictionString</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>51759b5579bc_image</td>\n",
       "      <td>opacity 0.001026149956 414.0 1875.0 815.0 2368...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>65761e66de9f_image</td>\n",
       "      <td>opacity 0.001026149956 848.0 932.0 1148.0 1300...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   id                                   PredictionString\n",
       "0  51759b5579bc_image  opacity 0.001026149956 414.0 1875.0 815.0 2368...\n",
       "1  65761e66de9f_image  opacity 0.001026149956 848.0 932.0 1148.0 1300..."
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dim = 640 #1024, 256, 'original'\n",
    "test_dir = f'/kaggle/tmp/{split}/image'\n",
    "weights_dir = '/kaggle/input/siimcovid19-detection-models/yolov5x_fold1_nb_v19_best.pt'\n",
    "\n",
    "import torch\n",
    "#from IPython.display import Image, clear_output  # to display images\n",
    "\n",
    "#clear_output()\n",
    "#print('Setup complete. Using torch %s %s' % (torch.__version__, torch.cuda.get_device_properties(0) if torch.cuda.is_available() else 'CPU'))\n",
    "\n",
    "\n",
    "!python detect.py --weights $weights_dir\\\n",
    "--img 640\\\n",
    "--conf 0.001\\\n",
    "--iou 0.5\\\n",
    "--source $test_dir\\\n",
    "--save-txt --save-conf --augment\n",
    "\n",
    "\n",
    "def yolo2voc(image_height, image_width, bboxes):\n",
    "    \"\"\"\n",
    "    yolo => [xmid, ymid, w, h] (normalized)\n",
    "    voc  => [x1, y1, x2, y1]\n",
    "\n",
    "    \"\"\" \n",
    "    bboxes = bboxes.copy().astype(float) # otherwise all value will be 0 as voc_pascal dtype is np.int\n",
    "\n",
    "    bboxes[..., [0, 2]] = bboxes[..., [0, 2]]* image_width\n",
    "    bboxes[..., [1, 3]] = bboxes[..., [1, 3]]* image_height\n",
    "\n",
    "    bboxes[..., [0, 1]] = bboxes[..., [0, 1]] - bboxes[..., [2, 3]]/2\n",
    "    bboxes[..., [2, 3]] = bboxes[..., [0, 1]] + bboxes[..., [2, 3]]\n",
    "\n",
    "    return bboxes\n",
    "\n",
    "image_ids = [] # (num_images, )\n",
    "PredictionStrings = [] # (num_images, boxes_lst)\n",
    "\n",
    "for file_path in tqdm(glob('runs/detect/exp2/labels/*.txt')):\n",
    "    image_id = file_path.split('/')[-1].split('.')[0]\n",
    "    w, h = test_df.loc[test_df.id==image_id,['dim1', 'dim0']].values[0]\n",
    "    f = open(file_path, 'r')\n",
    "    data = np.array(f.read().replace('\\n', ' ').strip().split(' ')).astype(np.float32).reshape(-1, 6)\n",
    "    data = data[:, [0, 5, 1, 2, 3, 4]]\n",
    "    bboxes = list(np.round(np.concatenate((data[:, :2], np.round(yolo2voc(h, w, data[:, 2:]))), axis =1).reshape(-1), 12).astype(str))\n",
    "    new_bboxes = []\n",
    "    for idx in range(len(bboxes)):\n",
    "        if idx%6 == 0:\n",
    "            new_bboxes.append('opacity')\n",
    "        else :\n",
    "            new_bboxes.append(bboxes[idx])\n",
    "    image_ids.append(image_id)\n",
    "    PredictionStrings.append(' '.join(new_bboxes))\n",
    "\n",
    "\n",
    "pred_yolov5_fold1_df = pd.DataFrame({'id':image_ids,\n",
    "                        'PredictionString':PredictionStrings})\n",
    "pred_yolov5_fold1_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "limited-championship",
   "metadata": {
    "papermill": {
     "duration": 0.154092,
     "end_time": "2021-08-02T09:17:24.276340",
     "exception": false,
     "start_time": "2021-08-02T09:17:24.122248",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## yolov5 fold 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "controlled-fourth",
   "metadata": {
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2021-08-02T09:17:24.599654Z",
     "iopub.status.busy": "2021-08-02T09:17:24.598834Z",
     "iopub.status.idle": "2021-08-02T09:17:35.188303Z",
     "shell.execute_reply": "2021-08-02T09:17:35.187893Z",
     "shell.execute_reply.started": "2021-08-01T23:16:44.114268Z"
    },
    "papermill": {
     "duration": 10.759174,
     "end_time": "2021-08-02T09:17:35.188441",
     "exception": false,
     "start_time": "2021-08-02T09:17:24.429267",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(agnostic_nms=False, augment=True, classes=None, conf_thres=0.001, device='', exist_ok=False, img_size=640, iou_thres=0.5, name='exp', project='runs/detect', save_conf=True, save_txt=True, source='/kaggle/tmp/test/image', update=False, view_img=False, weights=['/kaggle/input/siimcovid19-detection-models/yolov5x_fold2_nb_v20_best.pt'])\r\n",
      "Fusing layers... \r\n",
      "image 1/2 /kaggle/tmp/test/image/51759b5579bc_image.png: 640x640 42 0. opacitys, Done. (0.178s)\r\n",
      "image 2/2 /kaggle/tmp/test/image/65761e66de9f_image.png: 640x640 36 0. opacitys, Done. (0.155s)\r\n",
      "Results saved to runs/detect/exp3\r\n",
      "2 labels saved to runs/detect/exp3/labels\r\n",
      "Done. (0.537s)\r\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22befbd3642b434b8eeb3dc737d8872a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>PredictionString</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>51759b5579bc_image</td>\n",
       "      <td>opacity 0.001051899977 1986.0 1073.0 2498.0 18...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>65761e66de9f_image</td>\n",
       "      <td>opacity 0.001035689958 1974.0 815.0 2366.0 124...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   id                                   PredictionString\n",
       "0  51759b5579bc_image  opacity 0.001051899977 1986.0 1073.0 2498.0 18...\n",
       "1  65761e66de9f_image  opacity 0.001035689958 1974.0 815.0 2366.0 124..."
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dim = 640 #1024, 256, 'original'\n",
    "test_dir = f'/kaggle/tmp/{split}/image'\n",
    "weights_dir = '/kaggle/input/siimcovid19-detection-models/yolov5x_fold2_nb_v20_best.pt'\n",
    "\n",
    "import torch\n",
    "#from IPython.display import Image, clear_output  # to display images\n",
    "\n",
    "#clear_output()\n",
    "#print('Setup complete. Using torch %s %s' % (torch.__version__, torch.cuda.get_device_properties(0) if torch.cuda.is_available() else 'CPU'))\n",
    "\n",
    "\n",
    "!python detect.py --weights $weights_dir\\\n",
    "--img 640\\\n",
    "--conf 0.001\\\n",
    "--iou 0.5\\\n",
    "--source $test_dir\\\n",
    "--save-txt --save-conf --augment\n",
    "\n",
    "\n",
    "def yolo2voc(image_height, image_width, bboxes):\n",
    "    \"\"\"\n",
    "    yolo => [xmid, ymid, w, h] (normalized)\n",
    "    voc  => [x1, y1, x2, y1]\n",
    "\n",
    "    \"\"\" \n",
    "    bboxes = bboxes.copy().astype(float) # otherwise all value will be 0 as voc_pascal dtype is np.int\n",
    "\n",
    "    bboxes[..., [0, 2]] = bboxes[..., [0, 2]]* image_width\n",
    "    bboxes[..., [1, 3]] = bboxes[..., [1, 3]]* image_height\n",
    "\n",
    "    bboxes[..., [0, 1]] = bboxes[..., [0, 1]] - bboxes[..., [2, 3]]/2\n",
    "    bboxes[..., [2, 3]] = bboxes[..., [0, 1]] + bboxes[..., [2, 3]]\n",
    "\n",
    "    return bboxes\n",
    "\n",
    "image_ids = [] # (num_images, )\n",
    "PredictionStrings = [] # (num_images, boxes_lst)\n",
    "\n",
    "for file_path in tqdm(glob('runs/detect/exp3/labels/*.txt')):\n",
    "    image_id = file_path.split('/')[-1].split('.')[0]\n",
    "    w, h = test_df.loc[test_df.id==image_id,['dim1', 'dim0']].values[0]\n",
    "    f = open(file_path, 'r')\n",
    "    data = np.array(f.read().replace('\\n', ' ').strip().split(' ')).astype(np.float32).reshape(-1, 6)\n",
    "    data = data[:, [0, 5, 1, 2, 3, 4]]\n",
    "    bboxes = list(np.round(np.concatenate((data[:, :2], np.round(yolo2voc(h, w, data[:, 2:]))), axis =1).reshape(-1), 12).astype(str))\n",
    "    new_bboxes = []\n",
    "    for idx in range(len(bboxes)):\n",
    "        if idx%6 == 0:\n",
    "            new_bboxes.append('opacity')\n",
    "        else :\n",
    "            new_bboxes.append(bboxes[idx])\n",
    "    image_ids.append(image_id)\n",
    "    PredictionStrings.append(' '.join(new_bboxes))\n",
    "\n",
    "\n",
    "pred_yolov5_fold2_df = pd.DataFrame({'id':image_ids,\n",
    "                        'PredictionString':PredictionStrings})\n",
    "pred_yolov5_fold2_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "light-companion",
   "metadata": {
    "papermill": {
     "duration": 0.152777,
     "end_time": "2021-08-02T09:17:35.496472",
     "exception": false,
     "start_time": "2021-08-02T09:17:35.343695",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## yolov5 fold 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "supreme-worship",
   "metadata": {
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2021-08-02T09:17:35.808412Z",
     "iopub.status.busy": "2021-08-02T09:17:35.807590Z",
     "iopub.status.idle": "2021-08-02T09:17:35.858805Z",
     "shell.execute_reply": "2021-08-02T09:17:35.858313Z",
     "shell.execute_reply.started": "2021-08-01T23:16:53.884242Z"
    },
    "papermill": {
     "duration": 0.209025,
     "end_time": "2021-08-02T09:17:35.858936",
     "exception": false,
     "start_time": "2021-08-02T09:17:35.649911",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# dim = 640 #1024, 256, 'original'\n",
    "# test_dir = f'/kaggle/tmp/{split}/image'\n",
    "# weights_dir = '/kaggle/input/siimcovid19-detection-models/yolov5x_fold3_nb_v21_best.pt'\n",
    "\n",
    "# import torch\n",
    "# #from IPython.display import Image, clear_output  # to display images\n",
    "\n",
    "# #clear_output()\n",
    "# #print('Setup complete. Using torch %s %s' % (torch.__version__, torch.cuda.get_device_properties(0) if torch.cuda.is_available() else 'CPU'))\n",
    "\n",
    "\n",
    "# !python detect.py --weights $weights_dir\\\n",
    "# --img 640\\\n",
    "# --conf 0.001\\\n",
    "# --iou 0.5\\\n",
    "# --source $test_dir\\\n",
    "# --save-txt --save-conf --augment\n",
    "\n",
    "\n",
    "# def yolo2voc(image_height, image_width, bboxes):\n",
    "#     \"\"\"\n",
    "#     yolo => [xmid, ymid, w, h] (normalized)\n",
    "#     voc  => [x1, y1, x2, y1]\n",
    "\n",
    "#     \"\"\" \n",
    "#     bboxes = bboxes.copy().astype(float) # otherwise all value will be 0 as voc_pascal dtype is np.int\n",
    "\n",
    "#     bboxes[..., [0, 2]] = bboxes[..., [0, 2]]* image_width\n",
    "#     bboxes[..., [1, 3]] = bboxes[..., [1, 3]]* image_height\n",
    "\n",
    "#     bboxes[..., [0, 1]] = bboxes[..., [0, 1]] - bboxes[..., [2, 3]]/2\n",
    "#     bboxes[..., [2, 3]] = bboxes[..., [0, 1]] + bboxes[..., [2, 3]]\n",
    "\n",
    "#     return bboxes\n",
    "\n",
    "# image_ids = [] # (num_images, )\n",
    "# PredictionStrings = [] # (num_images, boxes_lst)\n",
    "\n",
    "# for file_path in tqdm(glob('runs/detect/exp4/labels/*.txt')):\n",
    "#     image_id = file_path.split('/')[-1].split('.')[0]\n",
    "#     w, h = test_df.loc[test_df.id==image_id,['dim1', 'dim0']].values[0]\n",
    "#     f = open(file_path, 'r')\n",
    "#     data = np.array(f.read().replace('\\n', ' ').strip().split(' ')).astype(np.float32).reshape(-1, 6)\n",
    "#     data = data[:, [0, 5, 1, 2, 3, 4]]\n",
    "#     bboxes = list(np.round(np.concatenate((data[:, :2], np.round(yolo2voc(h, w, data[:, 2:]))), axis =1).reshape(-1), 12).astype(str))\n",
    "#     new_bboxes = []\n",
    "#     for idx in range(len(bboxes)):\n",
    "#         if idx%6 == 0:\n",
    "#             new_bboxes.append('opacity')\n",
    "#         else :\n",
    "#             new_bboxes.append(bboxes[idx])\n",
    "#     image_ids.append(image_id)\n",
    "#     PredictionStrings.append(' '.join(new_bboxes))\n",
    "\n",
    "\n",
    "# pred_yolov5_fold3_df = pd.DataFrame({'id':image_ids,\n",
    "#                         'PredictionString':PredictionStrings})\n",
    "# pred_yolov5_fold3_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "average-ridge",
   "metadata": {
    "papermill": {
     "duration": 0.153304,
     "end_time": "2021-08-02T09:17:36.166664",
     "exception": false,
     "start_time": "2021-08-02T09:17:36.013360",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## yolov5 fold 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "approximate-storage",
   "metadata": {
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2021-08-02T09:17:36.479521Z",
     "iopub.status.busy": "2021-08-02T09:17:36.478689Z",
     "iopub.status.idle": "2021-08-02T09:17:36.522237Z",
     "shell.execute_reply": "2021-08-02T09:17:36.521797Z",
     "shell.execute_reply.started": "2021-08-01T23:16:53.938247Z"
    },
    "papermill": {
     "duration": 0.201071,
     "end_time": "2021-08-02T09:17:36.522367",
     "exception": false,
     "start_time": "2021-08-02T09:17:36.321296",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# dim = 640 #1024, 256, 'original'\n",
    "# test_dir = f'/kaggle/tmp/{split}/image'\n",
    "# weights_dir = '/kaggle/input/siimcovid19-detection-models/yolov5x_fold4_nb_v22_best.pt'\n",
    "\n",
    "# import torch\n",
    "# #from IPython.display import Image, clear_output  # to display images\n",
    "\n",
    "# #clear_output()\n",
    "# #print('Setup complete. Using torch %s %s' % (torch.__version__, torch.cuda.get_device_properties(0) if torch.cuda.is_available() else 'CPU'))\n",
    "\n",
    "\n",
    "# !python detect.py --weights $weights_dir\\\n",
    "# --img 640\\\n",
    "# --conf 0.001\\\n",
    "# --iou 0.5\\\n",
    "# --source $test_dir\\\n",
    "# --save-txt --save-conf --augment\n",
    "\n",
    "\n",
    "# def yolo2voc(image_height, image_width, bboxes):\n",
    "#     \"\"\"\n",
    "#     yolo => [xmid, ymid, w, h] (normalized)\n",
    "#     voc  => [x1, y1, x2, y1]\n",
    "\n",
    "#     \"\"\" \n",
    "#     bboxes = bboxes.copy().astype(float) # otherwise all value will be 0 as voc_pascal dtype is np.int\n",
    "\n",
    "#     bboxes[..., [0, 2]] = bboxes[..., [0, 2]]* image_width\n",
    "#     bboxes[..., [1, 3]] = bboxes[..., [1, 3]]* image_height\n",
    "\n",
    "#     bboxes[..., [0, 1]] = bboxes[..., [0, 1]] - bboxes[..., [2, 3]]/2\n",
    "#     bboxes[..., [2, 3]] = bboxes[..., [0, 1]] + bboxes[..., [2, 3]]\n",
    "\n",
    "#     return bboxes\n",
    "\n",
    "# image_ids = [] # (num_images, )\n",
    "# PredictionStrings = [] # (num_images, boxes_lst)\n",
    "\n",
    "# for file_path in tqdm(glob('runs/detect/exp5/labels/*.txt')):\n",
    "#     image_id = file_path.split('/')[-1].split('.')[0]\n",
    "#     w, h = test_df.loc[test_df.id==image_id,['dim1', 'dim0']].values[0]\n",
    "#     f = open(file_path, 'r')\n",
    "#     data = np.array(f.read().replace('\\n', ' ').strip().split(' ')).astype(np.float32).reshape(-1, 6)\n",
    "#     data = data[:, [0, 5, 1, 2, 3, 4]]\n",
    "#     bboxes = list(np.round(np.concatenate((data[:, :2], np.round(yolo2voc(h, w, data[:, 2:]))), axis =1).reshape(-1), 12).astype(str))\n",
    "#     new_bboxes = []\n",
    "#     for idx in range(len(bboxes)):\n",
    "#         if idx%6 == 0:\n",
    "#             new_bboxes.append('opacity')\n",
    "#         else :\n",
    "#             new_bboxes.append(bboxes[idx])\n",
    "#     image_ids.append(image_id)\n",
    "#     PredictionStrings.append(' '.join(new_bboxes))\n",
    "\n",
    "\n",
    "# pred_yolov5_fold4_df = pd.DataFrame({'id':image_ids,\n",
    "#                         'PredictionString':PredictionStrings})\n",
    "# pred_yolov5_fold4_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "enabling-behavior",
   "metadata": {
    "papermill": {
     "duration": 0.153088,
     "end_time": "2021-08-02T09:17:36.828670",
     "exception": false,
     "start_time": "2021-08-02T09:17:36.675582",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# MMDetection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "widespread-notification",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-02T09:17:37.147422Z",
     "iopub.status.busy": "2021-08-02T09:17:37.146638Z",
     "iopub.status.idle": "2021-08-02T09:19:42.382399Z",
     "shell.execute_reply": "2021-08-02T09:19:42.380947Z",
     "shell.execute_reply.started": "2021-08-01T23:16:53.985235Z"
    },
    "papermill": {
     "duration": 125.400255,
     "end_time": "2021-08-02T09:19:42.382558",
     "exception": false,
     "start_time": "2021-08-02T09:17:36.982303",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing /kaggle/input/mmdet2100/mmdetection-2.10.0/addict-2.4.0-py3-none-any.whl\r\n",
      "Installing collected packages: addict\r\n",
      "Successfully installed addict-2.4.0\r\n",
      "Processing /kaggle/input/mmdet2100/mmdetection-2.10.0/yapf-0.31.0-py2.py3-none-any.whl\r\n",
      "Installing collected packages: yapf\r\n",
      "Successfully installed yapf-0.31.0\r\n",
      "Processing /kaggle/input/pycocotools202/pycocotools-2.0.2-cp37-cp37m-linux_x86_64.whl\r\n",
      "Requirement already satisfied: cython>=0.27.3 in /opt/conda/lib/python3.7/site-packages (from pycocotools==2.0.2) (0.29.23)\r\n",
      "Requirement already satisfied: setuptools>=18.0 in /opt/conda/lib/python3.7/site-packages (from pycocotools==2.0.2) (49.6.0.post20210108)\r\n",
      "Requirement already satisfied: matplotlib>=2.1.0 in /opt/conda/lib/python3.7/site-packages (from pycocotools==2.0.2) (3.4.1)\r\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib>=2.1.0->pycocotools==2.0.2) (1.3.1)\r\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.7/site-packages (from matplotlib>=2.1.0->pycocotools==2.0.2) (2.8.1)\r\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib>=2.1.0->pycocotools==2.0.2) (2.4.7)\r\n",
      "Requirement already satisfied: numpy>=1.16 in /opt/conda/lib/python3.7/site-packages (from matplotlib>=2.1.0->pycocotools==2.0.2) (1.19.5)\r\n",
      "Requirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.7/site-packages (from matplotlib>=2.1.0->pycocotools==2.0.2) (7.2.0)\r\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.7/site-packages (from matplotlib>=2.1.0->pycocotools==2.0.2) (0.10.0)\r\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from cycler>=0.10->matplotlib>=2.1.0->pycocotools==2.0.2) (1.15.0)\r\n",
      "Installing collected packages: pycocotools\r\n",
      "  Attempting uninstall: pycocotools\r\n",
      "    Found existing installation: pycocotools 2.0\r\n",
      "    Uninstalling pycocotools-2.0:\r\n",
      "      Successfully uninstalled pycocotools-2.0\r\n",
      "Successfully installed pycocotools-2.0.2\r\n",
      "Processing /kaggle/input/mmcvfull134/mmcv_full-1.3.4-cp37-cp37m-manylinux1_x86_64.whl\r\n",
      "Requirement already satisfied: Pillow in /opt/conda/lib/python3.7/site-packages (from mmcv-full==1.3.4) (7.2.0)\r\n",
      "Requirement already satisfied: opencv-python>=3 in /opt/conda/lib/python3.7/site-packages (from mmcv-full==1.3.4) (4.5.1.48)\r\n",
      "Requirement already satisfied: yapf in /opt/conda/lib/python3.7/site-packages (from mmcv-full==1.3.4) (0.31.0)\r\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.7/site-packages (from mmcv-full==1.3.4) (5.3.1)\r\n",
      "Requirement already satisfied: addict in /opt/conda/lib/python3.7/site-packages (from mmcv-full==1.3.4) (2.4.0)\r\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from mmcv-full==1.3.4) (1.19.5)\r\n",
      "Installing collected packages: mmcv-full\r\n",
      "Successfully installed mmcv-full-1.3.4\r\n",
      "Looking in links: ./\r\n",
      "Processing /kaggle/input/mmdetection2120/mmdetection-2.12.0\r\n",
      "Requirement already satisfied: matplotlib in /opt/conda/lib/python3.7/site-packages (from mmdet==2.12.0) (3.4.1)\r\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from mmdet==2.12.0) (1.19.5)\r\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from mmdet==2.12.0) (1.15.0)\r\n",
      "Requirement already satisfied: terminaltables in /opt/conda/lib/python3.7/site-packages (from mmdet==2.12.0) (3.1.0)\r\n",
      "Requirement already satisfied: pycocotools in /opt/conda/lib/python3.7/site-packages (from mmdet==2.12.0) (2.0.2)\r\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib->mmdet==2.12.0) (1.3.1)\r\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.7/site-packages (from matplotlib->mmdet==2.12.0) (2.8.1)\r\n",
      "Requirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.7/site-packages (from matplotlib->mmdet==2.12.0) (7.2.0)\r\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib->mmdet==2.12.0) (2.4.7)\r\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.7/site-packages (from matplotlib->mmdet==2.12.0) (0.10.0)\r\n",
      "Requirement already satisfied: cython>=0.27.3 in /opt/conda/lib/python3.7/site-packages (from pycocotools->mmdet==2.12.0) (0.29.23)\r\n",
      "Requirement already satisfied: setuptools>=18.0 in /opt/conda/lib/python3.7/site-packages (from pycocotools->mmdet==2.12.0) (49.6.0.post20210108)\r\n",
      "Building wheels for collected packages: mmdet\r\n",
      "  Building wheel for mmdet (setup.py) ... \u001b[?25l-\b \b\\\b \b|\b \bdone\r\n",
      "\u001b[?25h  Created wheel for mmdet: filename=mmdet-2.12.0-py3-none-any.whl size=592092 sha256=f378fff1dcc1706a4d62eba3848f42310eaa3532d8d5e70b918bca0e834764c0\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/05/b5/eb/d376ff42b05cded8c6f10ef2f138c8e0a68f40fcdbd33e8c15\r\n",
      "Successfully built mmdet\r\n",
      "Installing collected packages: mmdet\r\n",
      "Successfully installed mmdet-2.12.0\r\n"
     ]
    }
   ],
   "source": [
    "!pip install /kaggle/input/mmdet2100/mmdetection-2.10.0/addict-2.4.0-py3-none-any.whl\n",
    "!pip install /kaggle/input/mmdet2100/mmdetection-2.10.0/yapf-0.31.0-py2.py3-none-any.whl\n",
    "!pip install /kaggle/input/pycocotools202/pycocotools-2.0.2-cp37-cp37m-linux_x86_64.whl\n",
    "!pip install /kaggle/input/mmcvfull134/mmcv_full-1.3.4-cp37-cp37m-manylinux1_x86_64.whl\n",
    "!pip install /kaggle/input/mmdetection2120/mmdetection-2.12.0 -f ./ --no-index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "equal-documentation",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-02T09:19:42.737985Z",
     "iopub.status.busy": "2021-08-02T09:19:42.737033Z",
     "iopub.status.idle": "2021-08-02T09:20:02.337998Z",
     "shell.execute_reply": "2021-08-02T09:20:02.338669Z",
     "shell.execute_reply.started": "2021-08-01T23:18:55.652518Z"
    },
    "papermill": {
     "duration": 19.781354,
     "end_time": "2021-08-02T09:20:02.338829",
     "exception": false,
     "start_time": "2021-08-02T09:19:42.557475",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.12.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import yaml\n",
    "import time\n",
    "import json\n",
    "import cv2\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import GroupKFold, StratifiedKFold\n",
    "from tqdm.notebook import tqdm\n",
    "import seaborn as sns\n",
    "import torch\n",
    "from IPython.display import Image, clear_output\n",
    "from collections import Counter\n",
    "from ensemble_boxes import *\n",
    "import copy\n",
    "import os.path as osp\n",
    "import mmcv\n",
    "import mmdet\n",
    "import numpy as np\n",
    "import albumentations as A\n",
    "from mmdet.datasets.builder import DATASETS\n",
    "from mmdet.datasets.custom import CustomDataset\n",
    "from mmcv import Config\n",
    "from mmdet.apis import set_random_seed\n",
    "from mmdet.apis import inference_detector, init_detector, show_result_pyplot\n",
    "from mmdet.datasets import build_dataset\n",
    "from mmdet.models import build_detector\n",
    "from mmdet.apis import train_detector\n",
    "print(mmdet.__version__)\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "partial-wages",
   "metadata": {
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2021-08-02T09:20:02.701395Z",
     "iopub.status.busy": "2021-08-02T09:20:02.700596Z",
     "iopub.status.idle": "2021-08-02T09:20:13.739304Z",
     "shell.execute_reply": "2021-08-02T09:20:13.740204Z",
     "shell.execute_reply.started": "2021-08-01T23:21:55.437638Z"
    },
    "papermill": {
     "duration": 11.241303,
     "end_time": "2021-08-02T09:20:13.740423",
     "exception": false,
     "start_time": "2021-08-02T09:20:02.499120",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use load_from_local loader\n",
      "CascadeRCNN(\n",
      "  (backbone): ResNeXt(\n",
      "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "    (layer1): ResLayer(\n",
      "      (0): Bottleneck(\n",
      "        (conv1): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): Bottleneck(\n",
      "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (2): Bottleneck(\n",
      "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (layer2): ResLayer(\n",
      "      (0): Bottleneck(\n",
      "        (conv1): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): Bottleneck(\n",
      "        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (2): Bottleneck(\n",
      "        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (3): Bottleneck(\n",
      "        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (layer3): ResLayer(\n",
      "      (0): Bottleneck(\n",
      "        (conv1): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (2): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (3): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (4): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (5): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (6): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (7): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (8): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (9): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (10): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (11): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (12): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (13): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (14): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (15): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (16): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (17): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (18): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (19): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (20): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (21): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (22): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (layer4): ResLayer(\n",
      "      (0): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False)\n",
      "        (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): Bottleneck(\n",
      "        (conv1): Conv2d(2048, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "        (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (2): Bottleneck(\n",
      "        (conv1): Conv2d(2048, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "        (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  init_cfg={'type': 'Pretrained', 'checkpoint': 'open-mmlab://resnext101_32x4d'}\n",
      "  (neck): FPN(\n",
      "    (lateral_convs): ModuleList(\n",
      "      (0): ConvModule(\n",
      "        (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "      (1): ConvModule(\n",
      "        (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "      (2): ConvModule(\n",
      "        (conv): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "      (3): ConvModule(\n",
      "        (conv): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "    )\n",
      "    (fpn_convs): ModuleList(\n",
      "      (0): ConvModule(\n",
      "        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "      (1): ConvModule(\n",
      "        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "      (2): ConvModule(\n",
      "        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "      (3): ConvModule(\n",
      "        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  init_cfg={'type': 'Xavier', 'layer': 'Conv2d', 'distribution': 'uniform'}\n",
      "  (rpn_head): RPNHead(\n",
      "    (loss_cls): CrossEntropyLoss()\n",
      "    (loss_bbox): SmoothL1Loss()\n",
      "    (rpn_conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (rpn_cls): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (rpn_reg): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      "  init_cfg={'type': 'Normal', 'layer': 'Conv2d', 'std': 0.01}\n",
      "  (roi_head): CascadeRoIHead(\n",
      "    (bbox_roi_extractor): ModuleList(\n",
      "      (0): SingleRoIExtractor(\n",
      "        (roi_layers): ModuleList(\n",
      "          (0): RoIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, pool_mode=avg, aligned=True, use_torchvision=False)\n",
      "          (1): RoIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, pool_mode=avg, aligned=True, use_torchvision=False)\n",
      "          (2): RoIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, pool_mode=avg, aligned=True, use_torchvision=False)\n",
      "          (3): RoIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, pool_mode=avg, aligned=True, use_torchvision=False)\n",
      "        )\n",
      "      )\n",
      "      (1): SingleRoIExtractor(\n",
      "        (roi_layers): ModuleList(\n",
      "          (0): RoIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, pool_mode=avg, aligned=True, use_torchvision=False)\n",
      "          (1): RoIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, pool_mode=avg, aligned=True, use_torchvision=False)\n",
      "          (2): RoIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, pool_mode=avg, aligned=True, use_torchvision=False)\n",
      "          (3): RoIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, pool_mode=avg, aligned=True, use_torchvision=False)\n",
      "        )\n",
      "      )\n",
      "      (2): SingleRoIExtractor(\n",
      "        (roi_layers): ModuleList(\n",
      "          (0): RoIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, pool_mode=avg, aligned=True, use_torchvision=False)\n",
      "          (1): RoIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, pool_mode=avg, aligned=True, use_torchvision=False)\n",
      "          (2): RoIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, pool_mode=avg, aligned=True, use_torchvision=False)\n",
      "          (3): RoIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, pool_mode=avg, aligned=True, use_torchvision=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (bbox_head): ModuleList(\n",
      "      (0): Shared2FCBBoxHead(\n",
      "        (loss_cls): CrossEntropyLoss()\n",
      "        (loss_bbox): SmoothL1Loss()\n",
      "        (fc_cls): Linear(in_features=1024, out_features=2, bias=True)\n",
      "        (fc_reg): Linear(in_features=1024, out_features=4, bias=True)\n",
      "        (shared_convs): ModuleList()\n",
      "        (shared_fcs): ModuleList(\n",
      "          (0): Linear(in_features=12544, out_features=1024, bias=True)\n",
      "          (1): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "        )\n",
      "        (cls_convs): ModuleList()\n",
      "        (cls_fcs): ModuleList()\n",
      "        (reg_convs): ModuleList()\n",
      "        (reg_fcs): ModuleList()\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      init_cfg=[{'type': 'Normal', 'std': 0.01, 'override': {'name': 'fc_cls'}}, {'type': 'Normal', 'std': 0.001, 'override': {'name': 'fc_reg'}}, {'type': 'Xavier', 'layer': 'Linear', 'override': [{'name': 'shared_fcs'}, {'name': 'cls_fcs'}, {'name': 'reg_fcs'}]}]\n",
      "      (1): Shared2FCBBoxHead(\n",
      "        (loss_cls): CrossEntropyLoss()\n",
      "        (loss_bbox): SmoothL1Loss()\n",
      "        (fc_cls): Linear(in_features=1024, out_features=2, bias=True)\n",
      "        (fc_reg): Linear(in_features=1024, out_features=4, bias=True)\n",
      "        (shared_convs): ModuleList()\n",
      "        (shared_fcs): ModuleList(\n",
      "          (0): Linear(in_features=12544, out_features=1024, bias=True)\n",
      "          (1): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "        )\n",
      "        (cls_convs): ModuleList()\n",
      "        (cls_fcs): ModuleList()\n",
      "        (reg_convs): ModuleList()\n",
      "        (reg_fcs): ModuleList()\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      init_cfg=[{'type': 'Normal', 'std': 0.01, 'override': {'name': 'fc_cls'}}, {'type': 'Normal', 'std': 0.001, 'override': {'name': 'fc_reg'}}, {'type': 'Xavier', 'layer': 'Linear', 'override': [{'name': 'shared_fcs'}, {'name': 'cls_fcs'}, {'name': 'reg_fcs'}]}]\n",
      "      (2): Shared2FCBBoxHead(\n",
      "        (loss_cls): CrossEntropyLoss()\n",
      "        (loss_bbox): SmoothL1Loss()\n",
      "        (fc_cls): Linear(in_features=1024, out_features=2, bias=True)\n",
      "        (fc_reg): Linear(in_features=1024, out_features=4, bias=True)\n",
      "        (shared_convs): ModuleList()\n",
      "        (shared_fcs): ModuleList(\n",
      "          (0): Linear(in_features=12544, out_features=1024, bias=True)\n",
      "          (1): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "        )\n",
      "        (cls_convs): ModuleList()\n",
      "        (cls_fcs): ModuleList()\n",
      "        (reg_convs): ModuleList()\n",
      "        (reg_fcs): ModuleList()\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      init_cfg=[{'type': 'Normal', 'std': 0.01, 'override': {'name': 'fc_cls'}}, {'type': 'Normal', 'std': 0.001, 'override': {'name': 'fc_reg'}}, {'type': 'Xavier', 'layer': 'Linear', 'override': [{'name': 'shared_fcs'}, {'name': 'cls_fcs'}, {'name': 'reg_fcs'}]}]\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/mmdet/apis/inference.py:47: UserWarning: Class names are not saved in the checkpoint's meta data, use COCO classes by default.\n",
      "  warnings.warn('Class names are not saved in the checkpoint\\'s '\n"
     ]
    }
   ],
   "source": [
    "checkpoint = '/kaggle/input/siimcovid19-detection-models/cascade_rcnn_x101_32x4d_fpn_1x_fold0_epoch10_public_nb_v8.pth'\n",
    "cfg = '/kaggle/input/siimcovid19-detection-models/cascade_rcnn_x101_32x4d_fpn_1x_fold0_epoch10_public_nb_v8_config.py'\n",
    "\n",
    "cfg = Config.fromfile(cfg)\n",
    "\n",
    "cfg.classes = (\"Covid_Abnormality\")\n",
    "cfg.data.test.img_prefix = ''\n",
    "cfg.data.test.classes = cfg.classes\n",
    "\n",
    "# cfg.model.roi_head.bbox_head.num_classes = 1\n",
    "# cfg.model.bbox_head.num_classes = 1\n",
    "for head in cfg.model.roi_head.bbox_head:\n",
    "    head.num_classes = 1\n",
    "\n",
    "# Set seed thus the results are more reproducible\n",
    "cfg.seed = 211\n",
    "set_random_seed(211, deterministic=False)\n",
    "cfg.gpu_ids = [0]\n",
    "\n",
    "cfg.data.test.pipeline=[\n",
    "            dict(type='LoadImageFromFile'),\n",
    "            dict(\n",
    "                type='MultiScaleFlipAug',\n",
    "                img_scale=(1333, 800),\n",
    "                flip=False,\n",
    "                transforms=[\n",
    "                    dict(type='Resize', keep_ratio=True),\n",
    "                    dict(type='RandomFlip', direction='horizontal'),\n",
    "                    dict(\n",
    "                        type='Normalize',\n",
    "                        mean=[123.675, 116.28, 103.53],\n",
    "                        std=[58.395, 57.12, 57.375],\n",
    "                        to_rgb=True),\n",
    "                    dict(type='Pad', size_divisor=32),\n",
    "                    dict(type='DefaultFormatBundle'),\n",
    "                    dict(type='Collect', keys=['img'])\n",
    "                ])\n",
    "        ]\n",
    "\n",
    "cfg.test_pipeline = [\n",
    "            dict(type='LoadImageFromFile'),\n",
    "            dict(\n",
    "                type='MultiScaleFlipAug',\n",
    "                img_scale=(1333, 800),\n",
    "                flip=False,\n",
    "                transforms=[\n",
    "                    dict(type='Resize', keep_ratio=True),\n",
    "                    dict(type='RandomFlip', direction='horizontal'),\n",
    "                    dict(\n",
    "                        type='Normalize',\n",
    "                        mean=[123.675, 116.28, 103.53],\n",
    "                        std=[58.395, 57.12, 57.375],\n",
    "                        to_rgb=True),\n",
    "                    dict(type='Pad', size_divisor=32),\n",
    "                    dict(type='DefaultFormatBundle'),\n",
    "                    dict(type='Collect', keys=['img'])\n",
    "                ])\n",
    "        ]\n",
    "\n",
    "# cfg.data.samples_per_gpu = 4\n",
    "# cfg.data.workers_per_gpu = 4\n",
    "# cfg.model.test_cfg.nms.iou_threshold = 0.3\n",
    "cfg.model.test_cfg.rcnn.score_thr = 0.001\n",
    "\n",
    "model_test = init_detector(cfg, checkpoint, device='cuda:0')\n",
    "print(model_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "three-setting",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-02T09:20:14.074494Z",
     "iopub.status.busy": "2021-08-02T09:20:14.073871Z",
     "iopub.status.idle": "2021-08-02T09:20:14.125312Z",
     "shell.execute_reply": "2021-08-02T09:20:14.125759Z",
     "shell.execute_reply.started": "2021-08-01T23:22:07.443623Z"
    },
    "papermill": {
     "duration": 0.222796,
     "end_time": "2021-08-02T09:20:14.125903",
     "exception": false,
     "start_time": "2021-08-02T09:20:13.903107",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "def nms_one_img(preds, img_path, img_width, img_height):\n",
    "    # print('img width:', img_width)\n",
    "    # print('img height:', img_height)\n",
    "    boxes_list = []\n",
    "    scores_list = []\n",
    "    labels_list = []\n",
    "    weights = [1]\n",
    "    # print(preds)\n",
    "    for i, pred in enumerate(preds):\n",
    "        if len(pred):\n",
    "            for p in pred:\n",
    "                box = [0, 0, 0, 0]\n",
    "                box[0] = min(1.0, p[0] / img_width)\n",
    "                box[1] = min(1.0, p[1] / img_height)\n",
    "                box[2] = min(1.0, p[2] / img_width)\n",
    "                box[3] = min(1.0, p[3] / img_height)\n",
    "                # print(box)\n",
    "                for b in box:\n",
    "                    if b > 1:\n",
    "                        print(img_path)\n",
    "                boxes_list.append(box)\n",
    "                score = p[4].astype(float)\n",
    "                scores_list.append(score)\n",
    "                labels_list.append(i)\n",
    "    # print('Before:')\n",
    "    # print(boxes_list)\n",
    "    boxes_list, scores_list, labels_list = nms([boxes_list], [scores_list], [labels_list], weights=weights, iou_thr=0.6)\n",
    "    # print('After:')\n",
    "    # print(boxes_list)\n",
    "    return boxes_list, scores_list, labels_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "presidential-syndication",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-02T09:20:14.454840Z",
     "iopub.status.busy": "2021-08-02T09:20:14.454256Z",
     "iopub.status.idle": "2021-08-02T09:20:14.504079Z",
     "shell.execute_reply": "2021-08-02T09:20:14.503623Z",
     "shell.execute_reply.started": "2021-08-01T23:22:07.831131Z"
    },
    "papermill": {
     "duration": 0.216323,
     "end_time": "2021-08-02T09:20:14.504196",
     "exception": false,
     "start_time": "2021-08-02T09:20:14.287873",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def infer_img(model, img_path):\n",
    "    img = mmcv.imread(img_path)\n",
    "    result = inference_detector(model, img_path)\n",
    "    # print(img.shape)\n",
    "    # print(img.shape[0])\n",
    "    # print(img.shape[1])\n",
    "    boxes_list, scores_list, labels_list = nms_one_img(result, img_path, img.shape[1], img.shape[0])\n",
    "    return boxes_list, scores_list, labels_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "polar-cloud",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-02T09:20:14.832714Z",
     "iopub.status.busy": "2021-08-02T09:20:14.831932Z",
     "iopub.status.idle": "2021-08-02T09:20:14.882550Z",
     "shell.execute_reply": "2021-08-02T09:20:14.882051Z",
     "shell.execute_reply.started": "2021-08-01T23:22:08.845698Z"
    },
    "papermill": {
     "duration": 0.215872,
     "end_time": "2021-08-02T09:20:14.882672",
     "exception": false,
     "start_time": "2021-08-02T09:20:14.666800",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def round_float(str_float, dec=3):\n",
    "    return str(round(float(str_float), 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "artistic-command",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-02T09:20:15.215604Z",
     "iopub.status.busy": "2021-08-02T09:20:15.214786Z",
     "iopub.status.idle": "2021-08-02T09:20:15.264234Z",
     "shell.execute_reply": "2021-08-02T09:20:15.263816Z",
     "shell.execute_reply.started": "2021-08-01T23:22:09.698465Z"
    },
    "papermill": {
     "duration": 0.219235,
     "end_time": "2021-08-02T09:20:15.264377",
     "exception": false,
     "start_time": "2021-08-02T09:20:15.045142",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def convert_to_df_row_list(img_id, boxes_list, scores_list, labels_list):\n",
    "    res = []\n",
    "    res.append(img_id)\n",
    "    prediction_string = ''\n",
    "    for i, label in enumerate(labels_list):\n",
    "        if int(label) == 1:\n",
    "            prediction_string = 'none 1 0 0 1 1'\n",
    "            continue\n",
    "        else:\n",
    "            prediction_string += 'opacity'\n",
    "        prediction_string += ' '\n",
    "        prediction_string += str(round(float(scores_list[i]), 3))\n",
    "        prediction_string += ' '\n",
    "        prediction_string += round_float(boxes_list[i][0], 3) + ' ' + round_float(boxes_list[i][1], 3) + ' ' + round_float(boxes_list[i][2], 3) + ' ' + round_float(boxes_list[i][3], 3) + ' '\n",
    "    res.append(prediction_string.rstrip())\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "boolean-stationery",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-02T09:20:15.595213Z",
     "iopub.status.busy": "2021-08-02T09:20:15.594470Z",
     "iopub.status.idle": "2021-08-02T09:20:17.010915Z",
     "shell.execute_reply": "2021-08-02T09:20:17.010459Z",
     "shell.execute_reply.started": "2021-08-01T23:22:10.193021Z"
    },
    "papermill": {
     "duration": 1.58556,
     "end_time": "2021-08-02T09:20:17.011043",
     "exception": false,
     "start_time": "2021-08-02T09:20:15.425483",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "vfnet_pred_lst = []\n",
    "test_dir = f'/kaggle/tmp/{split}/image'\n",
    "count = 0\n",
    "\n",
    "for img_name in os.listdir(test_dir):\n",
    "    img_path = test_dir + '/' + img_name\n",
    "    # boxes_list, scores_list, labels_list = infer_img(model, '../vinbigdata-cocodataset/ori_vinbigdata_3xdownsampled/test/test/b461cd28bc17c294dd986d0d91577ac3.jpg')\n",
    "    boxes_list, scores_list, labels_list = infer_img(model_test, img_path)\n",
    "    # print(boxes_list)\n",
    "    # print(scores_list)\n",
    "    # print(labels_list)\n",
    "    image_id = img_name.split('.png')[0]\n",
    "    ori_img_width = test_df[test_df.id == image_id]['dim1'].iloc[0]\n",
    "    ori_img_height = test_df[test_df.id == image_id]['dim0'].iloc[0]\n",
    "    boxes_list[:, 0] = boxes_list[:, 0] * ori_img_width\n",
    "    boxes_list[:, 2] = boxes_list[:, 2] * ori_img_width\n",
    "    boxes_list[:, 1] = boxes_list[:, 1] * ori_img_height\n",
    "    boxes_list[:, 3] = boxes_list[:, 3] * ori_img_height\n",
    "    df_row_lst = convert_to_df_row_list(image_id, boxes_list, scores_list, labels_list)\n",
    "    vfnet_pred_lst.append(df_row_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "nasty-emergency",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-02T09:20:17.339910Z",
     "iopub.status.busy": "2021-08-02T09:20:17.339123Z",
     "iopub.status.idle": "2021-08-02T09:20:17.393885Z",
     "shell.execute_reply": "2021-08-02T09:20:17.394254Z",
     "shell.execute_reply.started": "2021-08-01T23:22:11.615621Z"
    },
    "papermill": {
     "duration": 0.221973,
     "end_time": "2021-08-02T09:20:17.394411",
     "exception": false,
     "start_time": "2021-08-02T09:20:17.172438",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>PredictionString</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>65761e66de9f_image</td>\n",
       "      <td>opacity 0.805 1810.332 806.626 2422.337 1523.4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>51759b5579bc_image</td>\n",
       "      <td>opacity 0.747 158.294 1842.22 1015.081 2506.00...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   id                                   PredictionString\n",
       "0  65761e66de9f_image  opacity 0.805 1810.332 806.626 2422.337 1523.4...\n",
       "1  51759b5579bc_image  opacity 0.747 158.294 1842.22 1015.081 2506.00..."
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vfnet_pred_df = pd.DataFrame(vfnet_pred_lst, columns=['id', 'PredictionString'])\n",
    "vfnet_pred_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "verbal-digit",
   "metadata": {
    "papermill": {
     "duration": 0.28552,
     "end_time": "2021-08-02T09:20:17.849047",
     "exception": false,
     "start_time": "2021-08-02T09:20:17.563527",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Detection Emsemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "selective-seller",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-02T09:20:18.386642Z",
     "iopub.status.busy": "2021-08-02T09:20:18.385767Z",
     "iopub.status.idle": "2021-08-02T09:20:19.278061Z",
     "shell.execute_reply": "2021-08-02T09:20:19.278748Z",
     "shell.execute_reply.started": "2021-08-01T23:22:12.682191Z"
    },
    "papermill": {
     "duration": 1.173042,
     "end_time": "2021-08-02T09:20:19.278969",
     "exception": false,
     "start_time": "2021-08-02T09:20:18.105927",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from ensemble_boxes import nms, soft_nms, non_maximum_weighted, weighted_boxes_fusion\n",
    "\n",
    "# %%\n",
    "''' Merge output of two models after 2cls filter\n",
    "- Detectron2: https://www.kaggle.com/corochann/vinbigdata-detectron2-prediction\n",
    "- Yolov5: https://www.kaggle.com/awsaf49/vinbigdata-2-class-filter\n",
    "Reference:\n",
    "- https://github.com/ZFTurbo/Weighted-Boxes-Fusion\n",
    "'''\n",
    "\n",
    "# %%\n",
    "weights = [54, 54, 54, 58, 58, 54]\n",
    "iou_thr = 0.6\n",
    "skip_box_thr = 0.01 # 0.0001 for non soft-nms\n",
    "sigma = 0.1\n",
    "\n",
    "# %%\n",
    "test_meta = test_df\n",
    "merged_df = pd.DataFrame(columns=['id', 'PredictionString'])\n",
    "\n",
    "# %%\n",
    "'''Weighted Boxes Fusion'''\n",
    "image_id_lst = pred_yolov5_fold0_df['id'].unique()\n",
    "\n",
    "# %%\n",
    "# Helper functions\n",
    "def extract_data(data, img_height, img_width):\n",
    "    boxes_lst = []\n",
    "    scores_lst = []\n",
    "    labels_lst = []\n",
    "    data_lst = data.split(' ')\n",
    "    for i in range(0, len(data_lst), 6):\n",
    "        labels_lst.append(0)\n",
    "        scores_lst.append(float(data_lst[i + 1]))\n",
    "        x_min = float(data_lst[i + 2]) / img_width\n",
    "        y_min = float(data_lst[i + 3]) / img_height\n",
    "        x_max = float(data_lst[i + 4]) / img_width\n",
    "        y_max = float(data_lst[i + 5]) / img_height\n",
    "        boxes_lst.append([x_min, y_min, x_max, y_max])\n",
    "    return boxes_lst, scores_lst, labels_lst\n",
    "\n",
    "def convert_data_to_row(boxes, scores, labels):\n",
    "    data_lst = []\n",
    "    for i in range(len(boxes)):\n",
    "        data_lst.append('opacity')\n",
    "        data_lst.append(str(scores[i]))\n",
    "        data_lst.append(str(boxes[i][0]))\n",
    "        data_lst.append(str(boxes[i][1]))\n",
    "        data_lst.append(str(boxes[i][2]))\n",
    "        data_lst.append(str(boxes[i][3]))\n",
    "    data = ' '.join(data_lst)\n",
    "    return data\n",
    "\n",
    "def get_height_width(image_id):\n",
    "    # dim0: heigth, dim1: width\n",
    "    height = test_meta[test_meta['id'] == image_id]['dim0'].values[0]\n",
    "    width = test_meta[test_meta['id'] == image_id]['dim1'].values[0]\n",
    "    return height, width\n",
    "\n",
    "def scale_data(boxes, img_height, img_width):\n",
    "    res = []\n",
    "    for box in boxes:\n",
    "        temp = []\n",
    "        temp.append(box[0] * img_width)\n",
    "        temp.append(box[1] * img_height)\n",
    "        temp.append(box[2] * img_width)\n",
    "        temp.append(box[3] * img_height)\n",
    "        res.append(temp)\n",
    "    return res\n",
    "\n",
    "# %%\n",
    "def wbf(image_id):\n",
    "    img_height, img_width = get_height_width(image_id)\n",
    "    boxes_lst, scores_lst, labels_lst = [], [], []\n",
    "\n",
    "    pred_yolov5_fold0_data = pred_yolov5_fold0_df[pred_yolov5_fold0_df['id'] == image_id]['PredictionString'].values[0]\n",
    "    model_boxes_lst, model_scores_lst, model_labels_lst = extract_data(pred_yolov5_fold0_data, img_height, img_width)\n",
    "    boxes_lst.append(model_boxes_lst)\n",
    "    scores_lst.append(model_scores_lst)\n",
    "    labels_lst.append(model_labels_lst)\n",
    "\n",
    "    pred_yolov5_fold1_data = pred_yolov5_fold1_df[pred_yolov5_fold1_df['id'] == image_id]['PredictionString'].values[0]\n",
    "    model_boxes_lst, model_scores_lst, model_labels_lst = extract_data(pred_yolov5_fold1_data, img_height, img_width)\n",
    "    boxes_lst.append(model_boxes_lst)\n",
    "    scores_lst.append(model_scores_lst)\n",
    "    labels_lst.append(model_labels_lst)\n",
    "\n",
    "    pred_yolov5_fold2_data = pred_yolov5_fold2_df[pred_yolov5_fold2_df['id'] == image_id]['PredictionString'].values[0]\n",
    "    model_boxes_lst, model_scores_lst, model_labels_lst = extract_data(pred_yolov5_fold2_data, img_height, img_width)\n",
    "    boxes_lst.append(model_boxes_lst)\n",
    "    scores_lst.append(model_scores_lst)\n",
    "    labels_lst.append(model_labels_lst)\n",
    "\n",
    "#     pred_yolov5_fold3_data = pred_yolov5_fold3_df[pred_yolov5_fold3_df['id'] == image_id]['PredictionString'].values[0]\n",
    "#     model_boxes_lst, model_scores_lst, model_labels_lst = extract_data(pred_yolov5_fold3_data, img_height, img_width)\n",
    "#     boxes_lst.append(model_boxes_lst)\n",
    "#     scores_lst.append(model_scores_lst)\n",
    "#     labels_lst.append(model_labels_lst)\n",
    "\n",
    "#     pred_yolov5_fold4_data = pred_yolov5_fold4_df[pred_yolov5_fold4_df['id'] == image_id]['PredictionString'].values[0]\n",
    "#     model_boxes_lst, model_scores_lst, model_labels_lst = extract_data(pred_yolov5_fold4_data, img_height, img_width)\n",
    "#     boxes_lst.append(model_boxes_lst)\n",
    "#     scores_lst.append(model_scores_lst)\n",
    "#     labels_lst.append(model_labels_lst)\n",
    "    \n",
    "#     effdet_fold0_data = effdet_fold0[effdet_fold0['id'] == image_id]['PredictionString'].values[0]\n",
    "#     model_boxes_lst, model_scores_lst, model_labels_lst = extract_data(effdet_fold0_data, img_height, img_width)\n",
    "#     boxes_lst.append(model_boxes_lst)\n",
    "#     scores_lst.append(model_scores_lst)\n",
    "#     labels_lst.append(model_labels_lst)\n",
    "    \n",
    "#     effdet_fold1_data = effdet_fold1[effdet_fold1['id'] == image_id]['PredictionString'].values[0]\n",
    "#     model_boxes_lst, model_scores_lst, model_labels_lst = extract_data(effdet_fold1_data, img_height, img_width)\n",
    "#     boxes_lst.append(model_boxes_lst)\n",
    "#     scores_lst.append(model_scores_lst)\n",
    "#     labels_lst.append(model_labels_lst)\n",
    "    \n",
    "#     effdet_fold2_data = effdet_fold2[effdet_fold2['id'] == image_id]['PredictionString'].values[0]\n",
    "#     model_boxes_lst, model_scores_lst, model_labels_lst = extract_data(effdet_fold2_data, img_height, img_width)\n",
    "#     boxes_lst.append(model_boxes_lst)\n",
    "#     scores_lst.append(model_scores_lst)\n",
    "#     labels_lst.append(model_labels_lst)\n",
    "    \n",
    "    effdet_fold3_data = effdet_fold3[effdet_fold3['id'] == image_id]['PredictionString'].values[0]\n",
    "    model_boxes_lst, model_scores_lst, model_labels_lst = extract_data(effdet_fold3_data, img_height, img_width)\n",
    "    boxes_lst.append(model_boxes_lst)\n",
    "    scores_lst.append(model_scores_lst)\n",
    "    labels_lst.append(model_labels_lst)\n",
    "    \n",
    "    effdet_fold4_data = effdet_fold4[effdet_fold4['id'] == image_id]['PredictionString'].values[0]\n",
    "    model_boxes_lst, model_scores_lst, model_labels_lst = extract_data(effdet_fold4_data, img_height, img_width)\n",
    "    boxes_lst.append(model_boxes_lst)\n",
    "    scores_lst.append(model_scores_lst)\n",
    "    labels_lst.append(model_labels_lst)\n",
    "    \n",
    "    vfnet_pred_data = vfnet_pred_df[vfnet_pred_df['id'] == image_id]['PredictionString'].values[0]\n",
    "    model_boxes_lst, model_scores_lst, model_labels_lst = extract_data(vfnet_pred_data, img_height, img_width)\n",
    "    boxes_lst.append(model_boxes_lst)\n",
    "    scores_lst.append(model_scores_lst)\n",
    "    labels_lst.append(model_labels_lst)\n",
    "\n",
    "    boxes, scores, labels = weighted_boxes_fusion(boxes_lst, scores_lst, labels_lst, weights=weights, iou_thr=iou_thr, skip_box_thr=skip_box_thr)\n",
    "    # boxes, scores, labels = non_maximum_weighted(boxes_lst, scores_lst, labels_lst, weights=weights, iou_thr=iou_thr, skip_box_thr=skip_box_thr)\n",
    "    # boxes, scores, labels = nms(boxes_lst, scores_lst, labels_lst, weights=weights, iou_thr=iou_thr)\n",
    "    # boxes, scores, labels = soft_nms(boxes_lst, scores_lst, labels_lst, weights=weights, iou_thr=iou_thr, sigma=sigma, thresh=skip_box_thr)\n",
    "    boxes = scale_data(boxes, img_height, img_width)\n",
    "    # return boxes, scores, labels\n",
    "    merged_data = convert_data_to_row(boxes, scores, labels)\n",
    "    merged_data = pd.DataFrame([[image_id, merged_data]], columns=['id', 'PredictionString'])\n",
    "    return merged_data\n",
    "\n",
    "# %%\n",
    "# Test\n",
    "# test_boxes, test_scores, test_labels = wbf(image_id_lst[0])\n",
    "test_wbf = wbf(image_id_lst[0])\n",
    "\n",
    "# %%\n",
    "for image_id in image_id_lst:\n",
    "    merged_data = wbf(image_id)\n",
    "    merged_df = merged_df.append(merged_data, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "exposed-republic",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-02T09:20:19.661927Z",
     "iopub.status.busy": "2021-08-02T09:20:19.661141Z",
     "iopub.status.idle": "2021-08-02T09:20:19.715990Z",
     "shell.execute_reply": "2021-08-02T09:20:19.716411Z",
     "shell.execute_reply.started": "2021-08-01T23:22:13.326435Z"
    },
    "papermill": {
     "duration": 0.222881,
     "end_time": "2021-08-02T09:20:19.716558",
     "exception": false,
     "start_time": "2021-08-02T09:20:19.493677",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>PredictionString</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>51759b5579bc_image</td>\n",
       "      <td>opacity 0.3920193612575531 159.31273866444826 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>65761e66de9f_image</td>\n",
       "      <td>opacity 0.3600524067878723 1834.7672883868217 ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   id                                   PredictionString\n",
       "0  51759b5579bc_image  opacity 0.3920193612575531 159.31273866444826 ...\n",
       "1  65761e66de9f_image  opacity 0.3600524067878723 1834.7672883868217 ..."
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "theoretical-mistake",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-02T09:20:20.051373Z",
     "iopub.status.busy": "2021-08-02T09:20:20.050580Z",
     "iopub.status.idle": "2021-08-02T09:20:20.108184Z",
     "shell.execute_reply": "2021-08-02T09:20:20.108704Z",
     "shell.execute_reply.started": "2021-08-01T23:22:13.38776Z"
    },
    "papermill": {
     "duration": 0.227033,
     "end_time": "2021-08-02T09:20:20.108862",
     "exception": false,
     "start_time": "2021-08-02T09:20:19.881829",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>PredictionString</th>\n",
       "      <th>id_last_str</th>\n",
       "      <th>dim0</th>\n",
       "      <th>dim1</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>65761e66de9f_image</td>\n",
       "      <td>none 1 0 0 1 1</td>\n",
       "      <td>e</td>\n",
       "      <td>2330</td>\n",
       "      <td>2783</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>51759b5579bc_image</td>\n",
       "      <td>none 1 0 0 1 1</td>\n",
       "      <td>e</td>\n",
       "      <td>3093</td>\n",
       "      <td>2850</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   id PredictionString id_last_str  dim0  dim1 split\n",
       "0  65761e66de9f_image   none 1 0 0 1 1           e  2330  2783  test\n",
       "1  51759b5579bc_image   none 1 0 0 1 1           e  3093  2850  test"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "foreign-timber",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-02T09:20:20.441178Z",
     "iopub.status.busy": "2021-08-02T09:20:20.440427Z",
     "iopub.status.idle": "2021-08-02T09:20:20.501770Z",
     "shell.execute_reply": "2021-08-02T09:20:20.501279Z",
     "shell.execute_reply.started": "2021-08-01T23:22:13.448781Z"
    },
    "papermill": {
     "duration": 0.228972,
     "end_time": "2021-08-02T09:20:20.501886",
     "exception": false,
     "start_time": "2021-08-02T09:20:20.272914",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>id_last_str</th>\n",
       "      <th>dim0</th>\n",
       "      <th>dim1</th>\n",
       "      <th>split</th>\n",
       "      <th>PredictionString</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>65761e66de9f_image</td>\n",
       "      <td>e</td>\n",
       "      <td>2330</td>\n",
       "      <td>2783</td>\n",
       "      <td>test</td>\n",
       "      <td>opacity 0.3600524067878723 1834.7672883868217 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>51759b5579bc_image</td>\n",
       "      <td>e</td>\n",
       "      <td>3093</td>\n",
       "      <td>2850</td>\n",
       "      <td>test</td>\n",
       "      <td>opacity 0.3920193612575531 159.31273866444826 ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   id id_last_str  dim0  dim1 split  \\\n",
       "0  65761e66de9f_image           e  2330  2783  test   \n",
       "1  51759b5579bc_image           e  3093  2850  test   \n",
       "\n",
       "                                    PredictionString  \n",
       "0  opacity 0.3600524067878723 1834.7672883868217 ...  \n",
       "1  opacity 0.3920193612575531 159.31273866444826 ...  "
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = test_df.drop(['PredictionString'], axis=1)\n",
    "sub_df = pd.merge(test_df, merged_df, on = 'id', how = 'left').fillna(\"none 1 0 0 1 1\")\n",
    "sub_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "leading-democrat",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-02T09:20:20.836813Z",
     "iopub.status.busy": "2021-08-02T09:20:20.836050Z",
     "iopub.status.idle": "2021-08-02T09:20:20.895292Z",
     "shell.execute_reply": "2021-08-02T09:20:20.895719Z",
     "shell.execute_reply.started": "2021-08-01T23:22:13.516199Z"
    },
    "papermill": {
     "duration": 0.228788,
     "end_time": "2021-08-02T09:20:20.895860",
     "exception": false,
     "start_time": "2021-08-02T09:20:20.667072",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>PredictionString</th>\n",
       "      <th>none</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>65761e66de9f_image</td>\n",
       "      <td>opacity 0.3600524067878723 1834.7672883868217 ...</td>\n",
       "      <td>0.129468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>51759b5579bc_image</td>\n",
       "      <td>opacity 0.3920193612575531 159.31273866444826 ...</td>\n",
       "      <td>0.753524</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   id                                   PredictionString  \\\n",
       "0  65761e66de9f_image  opacity 0.3600524067878723 1834.7672883868217 ...   \n",
       "1  51759b5579bc_image  opacity 0.3920193612575531 159.31273866444826 ...   \n",
       "\n",
       "       none  \n",
       "0  0.129468  \n",
       "1  0.753524  "
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub_df = sub_df[['id', 'PredictionString']]\n",
    "sub_df['none'] = df_2class['none']\n",
    "sub_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "extraordinary-grant",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-02T09:20:21.237912Z",
     "iopub.status.busy": "2021-08-02T09:20:21.237107Z",
     "iopub.status.idle": "2021-08-02T09:20:21.302822Z",
     "shell.execute_reply": "2021-08-02T09:20:21.303376Z",
     "shell.execute_reply.started": "2021-08-01T23:22:13.58222Z"
    },
    "papermill": {
     "duration": 0.240601,
     "end_time": "2021-08-02T09:20:21.303537",
     "exception": false,
     "start_time": "2021-08-02T09:20:21.062936",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n",
      "/opt/conda/lib/python3.7/site-packages/pandas/core/indexing.py:1763: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  isetter(loc, value)\n"
     ]
    }
   ],
   "source": [
    "for i in range(sub_df.shape[0]):\n",
    "    if sub_df.loc[i,'PredictionString'] == \"none 1 0 0 1 1\":\n",
    "        continue\n",
    "    sub_df_split = sub_df.loc[i,'PredictionString'].split()\n",
    "    none_score = float(sub_df.loc[i, 'none'])\n",
    "    sub_df_list = []\n",
    "    for j in range(int(len(sub_df_split) / 6)):\n",
    "        sub_df_list.append('opacity')\n",
    "        opacity_score = float(sub_df_split[6 * j + 1])\n",
    "        calibrated_opacity_score = opacity_score * ((1 - none_score) ** 0.5) \n",
    "        sub_df_list.append(str(calibrated_opacity_score))\n",
    "        sub_df_list.append(sub_df_split[6 * j + 2])\n",
    "        sub_df_list.append(sub_df_split[6 * j + 3])\n",
    "        sub_df_list.append(sub_df_split[6 * j + 4])\n",
    "        sub_df_list.append(sub_df_split[6 * j + 5])\n",
    "    sub_df.loc[i,'PredictionString'] = ' '.join(sub_df_list)\n",
    "for i in range(sub_df.shape[0]):\n",
    "    if sub_df.loc[i,'PredictionString'] != 'none 1 0 0 1 1':\n",
    "        sub_df.loc[i,'PredictionString'] = sub_df.loc[i,'PredictionString'] + ' none ' + str(sub_df.loc[i,'none']) + ' 0 0 1 1'\n",
    "sub_df = sub_df[['id', 'PredictionString']]   \n",
    "df_study = df_study[:study_len]\n",
    "df_study = df_study.append(sub_df).reset_index(drop=True)\n",
    "df_study.to_csv('/kaggle/working/submission.csv',index = False)  \n",
    "shutil.rmtree('/kaggle/working/yolov5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "contained-christopher",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-02T09:20:21.637439Z",
     "iopub.status.busy": "2021-08-02T09:20:21.636666Z",
     "iopub.status.idle": "2021-08-02T09:20:21.690397Z",
     "shell.execute_reply": "2021-08-02T09:20:21.690816Z",
     "shell.execute_reply.started": "2021-08-01T23:22:13.776208Z"
    },
    "papermill": {
     "duration": 0.222412,
     "end_time": "2021-08-02T09:20:21.690959",
     "exception": false,
     "start_time": "2021-08-02T09:20:21.468547",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>PredictionString</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00086460a852_study</td>\n",
       "      <td>negative 0.112 0 0 1 1 indeterminate 0.222 0 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000c9c05fd14_study</td>\n",
       "      <td>negative 0.042 0 0 1 1 indeterminate 0.053 0 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>65761e66de9f_image</td>\n",
       "      <td>opacity 0.33593724537384795 1834.7672883868217...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>51759b5579bc_image</td>\n",
       "      <td>opacity 0.19462346405137868 159.31273866444826...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   id                                   PredictionString\n",
       "0  00086460a852_study  negative 0.112 0 0 1 1 indeterminate 0.222 0 0...\n",
       "1  000c9c05fd14_study  negative 0.042 0 0 1 1 indeterminate 0.053 0 0...\n",
       "2  65761e66de9f_image  opacity 0.33593724537384795 1834.7672883868217...\n",
       "3  51759b5579bc_image  opacity 0.19462346405137868 159.31273866444826..."
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "august-diploma",
   "metadata": {
    "papermill": {
     "duration": 0.165348,
     "end_time": "2021-08-02T09:20:22.020775",
     "exception": false,
     "start_time": "2021-08-02T09:20:21.855427",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 444.058382,
   "end_time": "2021-08-02T09:20:24.041143",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-08-02T09:12:59.982761",
   "version": "2.3.3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "10f40f76c4df4b63a14761d3ab56b24b": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "1f57f92a8ceb4517a18989747f8ff23f": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "22befbd3642b434b8eeb3dc737d8872a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_b0ec6d22eddf428498d2bf40c3fa5970",
        "IPY_MODEL_99d0c2d693974546a775d1b13cf687e6",
        "IPY_MODEL_b796cf2bef174b3ab8c6826b1c4aa7a6"
       ],
       "layout": "IPY_MODEL_a93b9c4e4fc2431eaa9babad07e4f12b"
      }
     },
     "24d12a7a5c464afcb7586279d8952812": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "2d91b71059e748f2b16395e459864a0c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "2dcbc8e9ac81454290a77ce9f2226c5b": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "3960bada128c42f88425a77845dd7812": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "3a4e87603dd44a53858f908b52c343d1": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "4051cd7d55fd441a9fc85b2dd0d470ec": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "41126944cc0c4056afc6e0d13be26495": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_704c6233044f4f80a0db149bd1d8a713",
       "placeholder": "​",
       "style": "IPY_MODEL_e10765e00c1f4400999e7f960653b505",
       "value": " 2/2 [00:00&lt;00:00, 58.32it/s]"
      }
     },
     "48622209d6414ef3b55b67d885a9a36f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_3960bada128c42f88425a77845dd7812",
       "placeholder": "​",
       "style": "IPY_MODEL_9ced5206b17546f4a08089e0daf62ef5",
       "value": "100%"
      }
     },
     "4a621e8217214eecae2b5b9eb3990355": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_48622209d6414ef3b55b67d885a9a36f",
        "IPY_MODEL_894b2fefd91f45e1bbd2029c04677396",
        "IPY_MODEL_91c88185628b408ebae5528028ce8b3f"
       ],
       "layout": "IPY_MODEL_c88df57b84d14bf885c6b254e9361184"
      }
     },
     "4d86bc9a21014ae08910586b94101302": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_b1f6521e454145f2ba6509a5ed7d1149",
        "IPY_MODEL_c68d820f593345f19efe18b0d4a30b89",
        "IPY_MODEL_41126944cc0c4056afc6e0d13be26495"
       ],
       "layout": "IPY_MODEL_2dcbc8e9ac81454290a77ce9f2226c5b"
      }
     },
     "58ee838c84794cb8957baabd8d2a600a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "62e0118869c144128b813e76194f76cc": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "6d723df8a6664c37b0007f20cf1800b0": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "704c6233044f4f80a0db149bd1d8a713": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "894b2fefd91f45e1bbd2029c04677396": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_24d12a7a5c464afcb7586279d8952812",
       "max": 2.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_6d723df8a6664c37b0007f20cf1800b0",
       "value": 2.0
      }
     },
     "91c88185628b408ebae5528028ce8b3f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_1f57f92a8ceb4517a18989747f8ff23f",
       "placeholder": "​",
       "style": "IPY_MODEL_3a4e87603dd44a53858f908b52c343d1",
       "value": " 2/2 [00:00&lt;00:00, 55.54it/s]"
      }
     },
     "99d0c2d693974546a775d1b13cf687e6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_4051cd7d55fd441a9fc85b2dd0d470ec",
       "max": 2.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_e202a72edcd64a5bbc0829d284bd18a0",
       "value": 2.0
      }
     },
     "9ced5206b17546f4a08089e0daf62ef5": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "a93b9c4e4fc2431eaa9babad07e4f12b": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "afc0d7bbf15c4fd9b695151b9ffb21ba": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "b0ec6d22eddf428498d2bf40c3fa5970": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_d4c5d93cab644dbf81fcce9360efaa3e",
       "placeholder": "​",
       "style": "IPY_MODEL_ec45e8e3fcaa4e6b90cc7e5a74885cf2",
       "value": "100%"
      }
     },
     "b1f6521e454145f2ba6509a5ed7d1149": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_62e0118869c144128b813e76194f76cc",
       "placeholder": "​",
       "style": "IPY_MODEL_2d91b71059e748f2b16395e459864a0c",
       "value": "100%"
      }
     },
     "b796cf2bef174b3ab8c6826b1c4aa7a6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_10f40f76c4df4b63a14761d3ab56b24b",
       "placeholder": "​",
       "style": "IPY_MODEL_58ee838c84794cb8957baabd8d2a600a",
       "value": " 2/2 [00:00&lt;00:00, 59.02it/s]"
      }
     },
     "c68d820f593345f19efe18b0d4a30b89": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_afc0d7bbf15c4fd9b695151b9ffb21ba",
       "max": 2.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_e7d3291453ba49c996cdd9f984d1b8f3",
       "value": 2.0
      }
     },
     "c88df57b84d14bf885c6b254e9361184": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "d4c5d93cab644dbf81fcce9360efaa3e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "e10765e00c1f4400999e7f960653b505": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "e202a72edcd64a5bbc0829d284bd18a0": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "e7d3291453ba49c996cdd9f984d1b8f3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "ec45e8e3fcaa4e6b90cc7e5a74885cf2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
